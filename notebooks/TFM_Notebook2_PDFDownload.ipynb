{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyN3h/42oR8AvHwYJQ5dR7Hz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Notebook 2: PDF Downloading and Text Extraction\n","\n"],"metadata":{"id":"xIRWyIUVxbA_"}},{"cell_type":"markdown","source":["\n","# 1 . **Introduction and Objectives**\n","In the previous notebook, we successfully searched the arXiv API to generate a corpus of metadata related to **BiS2-based layered superconductors**.\n","\n","The objective of this notebook is to transition from metadata to raw data. We will:\n","1.  Iterate through the corpus generated in step 1.\n","2.  Download the full-text PDF for each entry.\n","3.  Extract plain text from these PDFs to prepare for Natural Language Processing (NLP) tasks.\n"],"metadata":{"id":"eNLFb5ogm6lY"}},{"cell_type":"markdown","source":["# 2 . Environment Setup\n"],"metadata":{"id":"OvET72zYxa-c"}},{"cell_type":"markdown","source":["## 2.1 Installation of dependencies\n","We will use **PyMuPDF** (imported as `fitz`), a high-performance library for data extraction from PDF files. It allows us to access the document structure and extract text with high fidelity."],"metadata":{"id":"GguHqzO4lxX6"}},{"cell_type":"code","source":["# Install dependencies\n","# Using -q to minimize log output for a cleaner notebook presentation\n","!pip install PyMuPDF -q"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FpECK9WVw_c8","executionInfo":{"status":"ok","timestamp":1769687308465,"user_tz":-60,"elapsed":14126,"user":{"displayName":"Dar√≠o Santos","userId":"05949316178413510452"}},"outputId":"1ee5fc51-cfb9-4eb4-e345-44c93bbb774a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"markdown","source":["## 2.2 Import Libraries\n","We utilize a combination of standard Python libraries for file and time management, alongside third-party tools for web requests and data processing.\n","\n","* **`requests`**: Used to fetch PDF binary data from arXiv URLs.\n","* **`fitz` (PyMuPDF)**: The core engine for parsing PDF documents and extracting text.\n","* **`pandas`**: Used to load and manipulate the corpus dataframe generated in the previous notebook."],"metadata":{"id":"fFuEAPb5lr26"}},{"cell_type":"code","source":["# IMPORT LIBRARIES\n","\n","\n","# --- Standard Library ---\n","import os\n","import re\n","import json\n","import time\n","import hashlib\n","import logging\n","from pathlib import Path\n","from datetime import datetime\n","from typing import Dict, List, Optional\n","\n","# --- Third-Party Data Science & Utilities ---\n","import requests\n","import fitz  # PyMuPDF\n","import pandas as pd\n","\n","# --- Google Colab Specifics ---\n","from google.colab import drive\n","from google.colab import userdata\n","\n","\n","#  SETUP & INITIALIZATION\n","\n","# Configure Logging\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n","logger = logging.getLogger(__name__)\n","\n","# Mount Google Drive\n","MOUNT_PATH = '/content/drive'\n","\n","if not os.path.exists(MOUNT_PATH):\n","    print(\"üîå Mounting Google Drive...\")\n","    drive.mount(MOUNT_PATH)\n","else:\n","    print(f\"‚úÖ Drive already mounted at {MOUNT_PATH}\")\n","\n","# Optional: Define Base Directory for the project immediately\n","# BASE_DIR = Path(MOUNT_PATH) / \"MyDrive/Research/PDFs\"\n","# BASE_DIR.mkdir(parents=True, exist_ok=True)"],"metadata":{"id":"9d-xSDYzw1dk","executionInfo":{"status":"ok","timestamp":1769687602815,"user_tz":-60,"elapsed":20697,"user":{"displayName":"Dar√≠o Santos","userId":"05949316178413510452"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"22ef4049-a4fa-46d7-924b-164a2c810fc9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["üîå Mounting Google Drive...\n","Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## 2.3 Global Configuration and Path Management\n","To maintain a structured and version-controlled workflow, we define a central `CorpusConfig` class. This configuration handles:\n","\n","1.  **Directory Management:** Automatically creating distinct folders for raw PDFs (`data/raw`) and processed text (`data/processed`).\n","2.  **Versioning:** Using a `CORPUS_VERSION` flag to separate different experimental runs without overwriting previous data.\n","3.  **Network Settings:** Defining timeouts and retry logic to handle potential instability when scraping the arXiv server."],"metadata":{"id":"ZL2xWx9JmE1t"}},{"cell_type":"code","source":["class CorpusConfig:\n","    \"\"\"\n","    Central configuration for local corpus management.\n","    Handles directory structures, versioning, and download settings.\n","    \"\"\"\n","\n","    # --- Metadata ---\n","    CORPUS_VERSION: str = \"v1.0\"\n","    CREATION_DATE: str = datetime.now().strftime(\"%Y-%m-%d\")\n","\n","    # --- Base Paths ---\n","    # TFM is the Root Project Folder\n","    BASE_DIR: Path = Path(\"/content/drive/My Drive/TFM\")\n","\n","    # --- Main Corpus Directories (Versioned) ---\n","    # These paths dynamically update based on the VERSION attribute above\n","    PDF_DIR: Path = BASE_DIR / \"data/raw/pdfs\" / f\"corpus_{CORPUS_VERSION}_pdfs\"\n","    TEXT_DIR: Path = BASE_DIR / \"data/processed\" / f\"corpus_{CORPUS_VERSION}_text_dumps\"\n","    EXTRACTION_DIR: Path = BASE_DIR / \"data/processed/extractions\" / f\"corpus_{CORPUS_VERSION}_txt_extractions\"\n","    LOG_DIR: Path = BASE_DIR / \"logs\"\n","\n","    # --- Sample & Testing Directories ---\n","    # Static paths for testing pipelines without affecting the main corpus\n","    SAMPLE_PDF_DIR: Path = BASE_DIR / \"data/raw/pdfs/sample_pdfs\"\n","    SAMPLE_TEXT_DIR: Path = BASE_DIR / \"data/processed/sample_text_dumps\"\n","    SAMPLE_EXTRACTION_DIR: Path = BASE_DIR / \"data/processed/extractions/sample_txt_extractions\"\n","\n","    # --- Validation ---\n","    GOLD_STD_DIR: Path = BASE_DIR / \"data/processed/extractions/gold_standard_extractions\"\n","\n","    # --- Network / Scraper Settings ---\n","    TIMEOUT: int = 15       # Seconds to wait for a request\n","    MAX_RETRIES: int = 3    # Number of retries for failed downloads\n","    RETRY_DELAY: int = 2    # Seconds to wait between retries\n","\n","    @classmethod\n","    def create_directories(cls):\n","        \"\"\"\n","        Utilities to auto-create the folder structure defined above.\n","        Uses exist_ok=True to prevent errors if folders already exist.\n","        \"\"\"\n","        directories = [\n","            cls.PDF_DIR, cls.TEXT_DIR, cls.EXTRACTION_DIR, cls.LOG_DIR,\n","            cls.SAMPLE_PDF_DIR, cls.SAMPLE_TEXT_DIR, cls.SAMPLE_EXTRACTION_DIR,\n","            cls.GOLD_STD_DIR\n","        ]\n","\n","        print(f\"üìÇ Initializing Directory Structure for {cls.CORPUS_VERSION}...\")\n","        for folder in directories:\n","            folder.mkdir(parents=True, exist_ok=True)\n","            # print(f\"   Checked: {folder}\") # Uncomment for verbose output\n","        print(\"‚úÖ Directory structure ready.\")\n","\n","# --- Execute Setup ---\n","\n","# Initialize the folder structure immediately\n","CorpusConfig.create_directories()\n","\n","# Quick verify of the active version\n","print(f\"üîß Configuration loaded for Corpus Version: {CorpusConfig.CORPUS_VERSION}\")"],"metadata":{"id":"87cWd4QHzLiV","executionInfo":{"status":"ok","timestamp":1769687605247,"user_tz":-60,"elapsed":2441,"user":{"displayName":"Dar√≠o Santos","userId":"05949316178413510452"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bdd3b621-785d-43b2-b28e-8a281b6545a8"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["üìÇ Initializing Directory Structure for v1.0...\n","‚úÖ Directory structure ready.\n","üîß Configuration loaded for Corpus Version: v1.0\n"]}]},{"cell_type":"markdown","source":["## 2.4 Loading the Corpus Metadata\n","We begin by loading the JSON corpus generated in **Notebook 1**. This file contains the metadata (titles, authors, arXiv IDs, links) for the papers we intend to download.\n","\n","We will:\n","1.  Load the raw JSON file.\n","2.  Inspect the JSON structure to confirm data integrity.\n","3.  Convert the list of papers into a **Pandas DataFrame** for efficient iteration and filtering."],"metadata":{"id":"qz42K_GymPev"}},{"cell_type":"code","source":["# --- Configuration ---\n","# Update the filename below to match the specific output from Notebook 1\n","INPUT_FILENAME = \"bis2_corpus_v1_20260114_102041.json\"\n","INPUT_PATH = CorpusConfig.BASE_DIR / \"data/corpora/01_raw/v1\" / INPUT_FILENAME\n","\n","# --- Load JSON ---\n","if INPUT_PATH.exists():\n","    with open(INPUT_PATH, \"r\", encoding=\"utf-8\") as f:\n","        corpus_json = json.load(f)\n","    print(f\"‚úÖ Corpus loaded successfully: {INPUT_FILENAME}\")\n","else:\n","    raise FileNotFoundError(f\"‚ùå Corpus file not found at: {INPUT_PATH}\")\n","\n","# --- JSON Structure Exploration ---\n","print(\"\\n\" + \"=\"*40)\n","print(\"üîç Top-level JSON keys:\")\n","print(\"=\"*40)\n","print(list(corpus_json.keys()))\n","\n","print(\"\\n\" + \"=\"*40)\n","print(\"üìÑ Inspecting 'papers' field (first entry):\")\n","print(\"=\"*40)\n","# Pretty print the first paper to verify structure\n","print(json.dumps(corpus_json[\"papers\"][0], indent=2))\n","\n","print(\"\\n\" + \"-\"*40)\n","print(f\"üìö Total papers in corpus: {len(corpus_json['papers'])}\")\n","print(\"-\"*40)\n","\n","# --- Convert to DataFrame ---\n","# We focus on the 'papers' list; metadata about the search itself is ignored here\n","df_corpus = pd.DataFrame(corpus_json[\"papers\"])\n","\n","print(\"\\n\" + \"=\"*40)\n","print(\"üìä DataFrame Summary:\")\n","print(\"=\"*40)\n","print(f\"Shape: {df_corpus.shape}\")\n","print(f\"Columns: {df_corpus.columns.tolist()}\")\n","\n","# Display the first few rows\n","df_corpus.head(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"sUfLNFo01Wp1","executionInfo":{"status":"ok","timestamp":1769687635035,"user_tz":-60,"elapsed":140,"user":{"displayName":"Dar√≠o Santos","userId":"05949316178413510452"}},"outputId":"26afbcfe-f3bf-47d6-de4b-693036bbf34b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Corpus loaded successfully: bis2_corpus_v1_20260114_102041.json\n","\n","========================================\n","üîç Top-level JSON keys:\n","========================================\n","['metadata', 'papers']\n","\n","========================================\n","üìÑ Inspecting 'papers' field (first entry):\n","========================================\n","{\n","  \"arxiv_id\": \"2406.01263v2\",\n","  \"entry_id\": \"http://arxiv.org/abs/2406.01263v2\",\n","  \"doi\": \"10.7566/JPSJ.93.074707\",\n","  \"title\": \"Pb Substitution Effects on Lattice and Electronic System of the BiS2-based Superconductors La(O F)BiS2\",\n","  \"abstract\": \"We examined the effect of Pb substitution in the layered superconductor LaO0.5F0.5Bi1-xPbxS2 (x=0~0.15) through the measurements of the resistivity, thermal expansion, specific heat, and Seebeck coefficient. These transport and thermal properties show anomalies at certain temperatures (T*) for x${\\\\geq}$0.08. The large thermal expansion anomalies, specific heat anomalies, and the existence of hystereses in the above measurements indicate a first-order structural phase transition at T*. Additionally, the Seebeck coefficient indicates that the anomalies at T* are related not only to the lattice system, but also to the electronic system. Superconductivity is not observed above 2 K at x=0.08, which is around the phase boundary where T* vanishes. The suppression of superconductivity around the structural phase boundary suggests a close relationship between the lattice and superconductivity.\",\n","  \"authors\": [\n","    \"Miku Sasaki\",\n","    \"Kotaro Inada\",\n","    \"Fumito Mori\",\n","    \"Takaaki Hirase\",\n","    \"Haruki Yamada\",\n","    \"Shota Shimoyama\",\n","    \"Yasushi Nakamura\",\n","    \"Tetta Nakamura\",\n","    \"Yoshiyuki Shibayama\",\n","    \"Naoki Momono\"\n","  ],\n","  \"authors_str\": \"Miku Sasaki, Kotaro Inada, Fumito Mori, Takaaki Hirase, Haruki Yamada, Shota Shimoyama, Yasushi Nakamura, Tetta Nakamura, Yoshiyuki Shibayama, Naoki Momono\",\n","  \"published\": \"2024-06-03T12:24:51+00:00\",\n","  \"updated\": \"2024-06-05T06:50:28+00:00\",\n","  \"year\": 2024,\n","  \"primary_category\": \"cond-mat.supr-con\",\n","  \"categories\": [\n","    \"cond-mat.supr-con\"\n","  ],\n","  \"pdf_url\": \"https://arxiv.org/pdf/2406.01263v2\",\n","  \"comment\": \"11 pages, 7 figures, to appear in JPSJ\",\n","  \"journal_ref\": \"J. Phys. Soc. Jpn. 93, 074707 (2024)\"\n","}\n","\n","----------------------------------------\n","üìö Total papers in corpus: 130\n","----------------------------------------\n","\n","========================================\n","üìä DataFrame Summary:\n","========================================\n","Shape: (130, 15)\n","Columns: ['arxiv_id', 'entry_id', 'doi', 'title', 'abstract', 'authors', 'authors_str', 'published', 'updated', 'year', 'primary_category', 'categories', 'pdf_url', 'comment', 'journal_ref']\n"]},{"output_type":"execute_result","data":{"text/plain":["       arxiv_id                           entry_id                     doi  \\\n","0  2406.01263v2  http://arxiv.org/abs/2406.01263v2  10.7566/JPSJ.93.074707   \n","1  2405.09129v2  http://arxiv.org/abs/2405.09129v2                    None   \n","2  2308.04081v2  http://arxiv.org/abs/2308.04081v2                    None   \n","\n","                                               title  \\\n","0  Pb Substitution Effects on Lattice and Electro...   \n","1  Aging Effects on Superconducting Properties of...   \n","2  Absence of Tc-Pinning Phenomenon Under High Pr...   \n","\n","                                            abstract  \\\n","0  We examined the effect of Pb substitution in t...   \n","1  Decomposition of superconductors sometimes bec...   \n","2  Recently, robustness of superconductivity (tra...   \n","\n","                                             authors  \\\n","0  [Miku Sasaki, Kotaro Inada, Fumito Mori, Takaa...   \n","1  [Poonam Rani, Rajveer Jha, V. P. S. Awana, Yos...   \n","2  [Yoshikazu Mizuguchi, Kazuki Yamane, Ryo Matsu...   \n","\n","                                         authors_str  \\\n","0  Miku Sasaki, Kotaro Inada, Fumito Mori, Takaak...   \n","1  Poonam Rani, Rajveer Jha, V. P. S. Awana, Yosh...   \n","2  Yoshikazu Mizuguchi, Kazuki Yamane, Ryo Matsum...   \n","\n","                   published                    updated  year  \\\n","0  2024-06-03T12:24:51+00:00  2024-06-05T06:50:28+00:00  2024   \n","1  2024-05-15T06:46:28+00:00  2024-06-25T15:26:31+00:00  2024   \n","2  2023-08-08T06:38:27+00:00  2023-09-12T03:06:13+00:00  2023   \n","\n","    primary_category                              categories  \\\n","0  cond-mat.supr-con                     [cond-mat.supr-con]   \n","1  cond-mat.supr-con                     [cond-mat.supr-con]   \n","2  cond-mat.supr-con  [cond-mat.supr-con, cond-mat.mtrl-sci]   \n","\n","                              pdf_url                                 comment  \\\n","0  https://arxiv.org/pdf/2406.01263v2  11 pages, 7 figures, to appear in JPSJ   \n","1  https://arxiv.org/pdf/2405.09129v2                     13 pages, 6 figures   \n","2  https://arxiv.org/pdf/2308.04081v2  10 pages, 4 figures, to appear in JPSJ   \n","\n","                            journal_ref  \n","0  J. Phys. Soc. Jpn. 93, 074707 (2024)  \n","1                                  None  \n","2                                  None  "],"text/html":["\n","  <div id=\"df-aa4a9a70-f007-420d-b07f-f1414c811f41\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>arxiv_id</th>\n","      <th>entry_id</th>\n","      <th>doi</th>\n","      <th>title</th>\n","      <th>abstract</th>\n","      <th>authors</th>\n","      <th>authors_str</th>\n","      <th>published</th>\n","      <th>updated</th>\n","      <th>year</th>\n","      <th>primary_category</th>\n","      <th>categories</th>\n","      <th>pdf_url</th>\n","      <th>comment</th>\n","      <th>journal_ref</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2406.01263v2</td>\n","      <td>http://arxiv.org/abs/2406.01263v2</td>\n","      <td>10.7566/JPSJ.93.074707</td>\n","      <td>Pb Substitution Effects on Lattice and Electro...</td>\n","      <td>We examined the effect of Pb substitution in t...</td>\n","      <td>[Miku Sasaki, Kotaro Inada, Fumito Mori, Takaa...</td>\n","      <td>Miku Sasaki, Kotaro Inada, Fumito Mori, Takaak...</td>\n","      <td>2024-06-03T12:24:51+00:00</td>\n","      <td>2024-06-05T06:50:28+00:00</td>\n","      <td>2024</td>\n","      <td>cond-mat.supr-con</td>\n","      <td>[cond-mat.supr-con]</td>\n","      <td>https://arxiv.org/pdf/2406.01263v2</td>\n","      <td>11 pages, 7 figures, to appear in JPSJ</td>\n","      <td>J. Phys. Soc. Jpn. 93, 074707 (2024)</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2405.09129v2</td>\n","      <td>http://arxiv.org/abs/2405.09129v2</td>\n","      <td>None</td>\n","      <td>Aging Effects on Superconducting Properties of...</td>\n","      <td>Decomposition of superconductors sometimes bec...</td>\n","      <td>[Poonam Rani, Rajveer Jha, V. P. S. Awana, Yos...</td>\n","      <td>Poonam Rani, Rajveer Jha, V. P. S. Awana, Yosh...</td>\n","      <td>2024-05-15T06:46:28+00:00</td>\n","      <td>2024-06-25T15:26:31+00:00</td>\n","      <td>2024</td>\n","      <td>cond-mat.supr-con</td>\n","      <td>[cond-mat.supr-con]</td>\n","      <td>https://arxiv.org/pdf/2405.09129v2</td>\n","      <td>13 pages, 6 figures</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2308.04081v2</td>\n","      <td>http://arxiv.org/abs/2308.04081v2</td>\n","      <td>None</td>\n","      <td>Absence of Tc-Pinning Phenomenon Under High Pr...</td>\n","      <td>Recently, robustness of superconductivity (tra...</td>\n","      <td>[Yoshikazu Mizuguchi, Kazuki Yamane, Ryo Matsu...</td>\n","      <td>Yoshikazu Mizuguchi, Kazuki Yamane, Ryo Matsum...</td>\n","      <td>2023-08-08T06:38:27+00:00</td>\n","      <td>2023-09-12T03:06:13+00:00</td>\n","      <td>2023</td>\n","      <td>cond-mat.supr-con</td>\n","      <td>[cond-mat.supr-con, cond-mat.mtrl-sci]</td>\n","      <td>https://arxiv.org/pdf/2308.04081v2</td>\n","      <td>10 pages, 4 figures, to appear in JPSJ</td>\n","      <td>None</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa4a9a70-f007-420d-b07f-f1414c811f41')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-aa4a9a70-f007-420d-b07f-f1414c811f41 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-aa4a9a70-f007-420d-b07f-f1414c811f41');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_corpus","summary":"{\n  \"name\": \"df_corpus\",\n  \"rows\": 130,\n  \"fields\": [\n    {\n      \"column\": \"arxiv_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 130,\n        \"samples\": [\n          \"1411.6903v1\",\n          \"1603.02819v1\",\n          \"1911.02337v1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"entry_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 130,\n        \"samples\": [\n          \"http://arxiv.org/abs/1411.6903v1\",\n          \"http://arxiv.org/abs/1603.02819v1\",\n          \"http://arxiv.org/abs/1911.02337v1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"doi\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 112,\n        \"samples\": [\n          \"10.7566/JPSJ.84.084703\",\n          \"10.1016/j.phpro.2014.09.032\",\n          \"10.1103/PhysRevB.103.245120\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 130,\n        \"samples\": [\n          \"Anomalous Eu Valence State and Superconductivity in Undoped Eu3Bi2S4F4\",\n          \"RVB States in doped Band Insulators from Coloumb forces: Theory and a case study of Superconductivity in BiS$_2$ Layers\",\n          \"Growth of superconducting Sm(O,F)BiS2 single crystals\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 130,\n        \"samples\": [\n          \"We have synthesized a novel europium bismuth sulfofluoride, Eu3Bi2S4F4, by solid-state reactions in sealed evacuated quartz ampoules. The compound crystallizes in a tetragonal lattice (space group I4/mmm, a = 4.0771(1) A, c = 32.4330(6) A, and Z = 2), in which CaF2-type Eu3F4 layers and NaCl-like BiS2 bilayers stack alternately along the crystallographic c axis. There are two crystallographically distinct Eu sites, Eu(1) and Eu(2) at the Wyckoff positions 4e and 2a, respectively. Our bond-valence-sum calculation, based on the refined structural data, indicates that Eu(1) is essentially divalent, whilst Eu(2) has an average valence of +2.64(5). This anomalous Eu valence state is further confirmed and supported, respectively, by Mossbauer and magnetization measurements. The Eu3+ components donate electrons into the conduction bands that are mainly composed of Bi- 6px and 6py states. Consequently, the material itself shows metallic conduction, and superconducts at 1.5 K without extrinsic chemical doping.\",\n          \"Doped band insulators, HfNCl, WO$_3$, diamond, Bi$_2$Se$_3$, \\\\bis2 families, STO/LAO interface, gate doped SrTiO$_3$ and MoS$_2$ etc. are unusual superconductors. With an aim to build a general theory for superconductivity in doped band insulators we focuss on \\\\bis2 family, discovered by Mizuguchi et al. in 2012. While maximum Tc is only $\\\\sim$ 11 K in \\\\laofx, a number of experimental results are puzzling and anomalous; they resemble high Tc and unconventional superconductors. Using a two orbital model of Usui, Suzuki and Kuroki we show that the uniform low density free fermi sea in \\\\laofh is \\\\textit{unstable towards formation of next nearest neighbor Bi-S-Bi diagonal valence bond} (charge -2e Cooper pair) and their \\\\textit{Wigner crystallization}. Instability to this novel state of matter is caused by unscreened nearest neighbor coulomb repulsions (V $\\\\sim$ 1 eV) and a hopping pattern with sulfur mediated diagonal next nearest neighbor Bi-S-Bi hopping t' $\\\\sim$ 0.88 eV, larger than nearest neighbor Bi-Bi hopping, t $\\\\sim$ 0.16 eV. Wigner crystal of Cooper pairs quantum melt for doping around x = 0.5 and stabilize certain resonating valence bond states and superconductivity. We study few variational RVB states and suggest that \\\\bis2 family members are latent high Tc superconductors, but challenged by competing orders and fragile nature of manybody states sustained by unscreened Coulomb forces. One of our superconducting state has d$_{xy}$ symmetry and a gap. We also predict 2d \\\\textit{Bose metal or vortex liquid} normal state, as charge -2e valence bonds survive in the normal state.\",\n          \"Superconducting Sm(O,F)BiS2 single crystals were successfully grown using KI-KCl flux. The obtained single crystals were flat-shaped and their size was 500um. The structure and composition of the obtained single crystals were obtained using X-ray diffraction and X-ray spectroscopy. The lattice constants of the obtained Sm(O,F)BiS2 single crystals were evaluated to be a = 3.9672(4) A and c = 13.417(6) A, while their F/(O + F) molar ratio was approximately 0.17. The superconducting transition temperature of the obtained Sm(O,F)BiS2 single crystals was 4.8 K. This was different from the reported Sm(O,F)BiS2 with no superconducting transition above 2 K. The superconducting anisotropies of the upper critical field and effective mass model of the obtained Sm(O,F)BiS2 single crystals were estimated to be approximately 26 and 10, respectively.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"authors\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"authors_str\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 121,\n        \"samples\": [\n          \"Masanori Nagao\",\n          \"M. A. Griffith, K. Foyevtsova, M. A. Continentino, G. B. Martins\",\n          \"Fysol Ibna Abbas, Kazuhisa Hoshi, Yuki Nakahira, Miku Yoshida, Aichi Yamashita, Hiroaki Ito, Akira Miura, Chikako Moriyoshi, Chul-Ho Lee, Yoshikazu Mizuguchi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"published\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 130,\n        \"samples\": [\n          \"2014-11-25T16:08:54+00:00\",\n          \"2016-03-09T09:27:06+00:00\",\n          \"2019-11-06T12:28:51+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"updated\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 130,\n        \"samples\": [\n          \"2014-11-25T16:08:54+00:00\",\n          \"2016-03-09T09:27:06+00:00\",\n          \"2019-11-06T12:28:51+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 2012,\n        \"max\": 2024,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          2013,\n          2015,\n          2024\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"primary_category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"cond-mat.supr-con\",\n          \"cond-mat.mtrl-sci\",\n          \"cond-mat.str-el\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"categories\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pdf_url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 130,\n        \"samples\": [\n          \"https://arxiv.org/pdf/1411.6903v1\",\n          \"https://arxiv.org/pdf/1603.02819v1\",\n          \"https://arxiv.org/pdf/1911.02337v1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 104,\n        \"samples\": [\n          \"Accepted by Scientific Reports. 14 pages, 4 Figures\",\n          \"17 pages text + Figs\",\n          \"10 pages, 3 figures; The lattice parameter c for the HP sample was revised\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"journal_ref\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 106,\n        \"samples\": [\n          \"Physica C, 483, 94-96 (2012)\",\n          \"Condens. Matter 5, 81(1-10) (2020)\",\n          \"Phys. Rev. B 103, 245120 (2021)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# --- CREATE A MANUAL SAMPLE FROM THE CORPUS ---\n","\n","sample_folder = \"/content/drive/MyDrive/TFM/data/raw/pdfs/sample_pdfs\"\n","\n","sample_ids = [\n","    '1508.04820v1', '1701.07575v1', '2001.07928v1', '1712.06815v1',\n","    '1210.1305v1', '1508.01656v1', '1409.2189v2', '1306.3346v2',\n","    '1404.6359v2', '1810.08404v3'\n","]\n","\n","# Filter corpus using predefined arXiv identifiers\n","sample_df = df_corpus[df_corpus[\"arxiv_id\"].isin(sample_ids)].copy()\n","\n","# --- BASIC VERIFICATION ---\n","\n","print(f\"Requested papers: {len(sample_ids)}\")\n","print(f\"Papers found in corpus: {len(sample_df)}\")\n","\n","missing_ids = set(sample_ids) - set(sample_df[\"arxiv_id\"])\n","if missing_ids:\n","    print(\"\\nMissing arXiv IDs:\")\n","    for mid in sorted(missing_ids):\n","        print(f\" - {mid}\")\n","else:\n","    print(\"\\nAll requested papers were found in the corpus.\")\n","\n","sample_df.head()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":681},"id":"b4nZwv4zH3SM","executionInfo":{"status":"ok","timestamp":1768473522762,"user_tz":-60,"elapsed":65,"user":{"displayName":"Dar√≠o Santos","userId":"05949316178413510452"}},"outputId":"78f8fbb3-1cfc-40d5-97fb-d3ad4d4cfc13"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requested papers: 10\n","Papers found in corpus: 10\n","\n","All requested papers were found in the corpus.\n"]},{"output_type":"execute_result","data":{"text/plain":["        arxiv_id                           entry_id  \\\n","17  2001.07928v1  http://arxiv.org/abs/2001.07928v1   \n","22  1810.08404v3  http://arxiv.org/abs/1810.08404v3   \n","27  1712.06815v1  http://arxiv.org/abs/1712.06815v1   \n","34  1701.07575v1  http://arxiv.org/abs/1701.07575v1   \n","47  1508.04820v1  http://arxiv.org/abs/1508.04820v1   \n","\n","                               doi  \\\n","17          10.7566/JPSJ.89.064702   \n","22                            None   \n","27          10.7566/JPSJ.87.023704   \n","34  10.1088/1742-6596/871/1/012007   \n","47       10.1016/j.ssc.2016.07.001   \n","\n","                                                title  \\\n","17  Bulk superconductivity induced by Se substitut...   \n","22  Bulk superconductivity in La2O2M4S6-type layer...   \n","27  Evolution of Anisotropic Displacement Paramete...   \n","34  Synchrotron powder X-ray diffraction and struc...   \n","47  Applying experimental constraints to a one-dim...   \n","\n","                                             abstract  \\\n","17  We report the Se substitution effects on the c...   \n","22  Recently, we reported the observation of super...   \n","27  In order to understand the mechanisms behind t...   \n","34  Eu0.5La0.5FBiS2-xSex is a new BiS2-based super...   \n","47  Recent ARPES measurements [Phys. Rev. B 92, 04...   \n","\n","                                              authors  \\\n","17  [Ryosuke Kiyama, Yosuke Goto, Kazuhisa Hoshi, ...   \n","22  [Rajveer Jha, Yosuke Goto, Tatsuma D. Matsuda,...   \n","27  [Yoshikazu Mizuguchi, Kazuhisa Hoshi, Yosuke G...   \n","34  [K. Nagasaka, G. Jinno, O. Miura, A. Miura, C....   \n","47  [M. A. Griffith, K. Foyevtsova, M. A. Continen...   \n","\n","                                          authors_str  \\\n","17  Ryosuke Kiyama, Yosuke Goto, Kazuhisa Hoshi, R...   \n","22  Rajveer Jha, Yosuke Goto, Tatsuma D. Matsuda, ...   \n","27  Yoshikazu Mizuguchi, Kazuhisa Hoshi, Yosuke Go...   \n","34  K. Nagasaka, G. Jinno, O. Miura, A. Miura, C. ...   \n","47  M. A. Griffith, K. Foyevtsova, M. A. Continent...   \n","\n","                    published                    updated  year  \\\n","17  2020-01-22T09:35:42+00:00  2020-01-22T09:35:42+00:00  2020   \n","22  2018-10-19T08:55:02+00:00  2019-04-15T07:46:09+00:00  2018   \n","27  2017-12-19T08:25:07+00:00  2017-12-19T08:25:07+00:00  2017   \n","34  2017-01-26T04:36:20+00:00  2017-01-26T04:36:20+00:00  2017   \n","47  2015-08-19T22:39:35+00:00  2015-08-19T22:39:35+00:00  2015   \n","\n","     primary_category                              categories  \\\n","17  cond-mat.supr-con  [cond-mat.supr-con, cond-mat.mtrl-sci]   \n","22  cond-mat.supr-con                     [cond-mat.supr-con]   \n","27  cond-mat.supr-con  [cond-mat.supr-con, cond-mat.mtrl-sci]   \n","34  cond-mat.supr-con                     [cond-mat.supr-con]   \n","47  cond-mat.supr-con    [cond-mat.supr-con, cond-mat.str-el]   \n","\n","                               pdf_url  \\\n","17  https://arxiv.org/pdf/2001.07928v1   \n","22  https://arxiv.org/pdf/1810.08404v3   \n","27  https://arxiv.org/pdf/1712.06815v1   \n","34  https://arxiv.org/pdf/1701.07575v1   \n","47  https://arxiv.org/pdf/1508.04820v1   \n","\n","                                              comment  \\\n","17                                15 pages, 8 figures   \n","22  18 Pages, 8 figures. The title has been change...   \n","27                                               None   \n","34  5 pages, 2 figures, to appear in proceedings o...   \n","47            4pages+references+supplemental material   \n","\n","                                 journal_ref  \n","17                                      None  \n","22        Scientific Reports 9, 13346 (2019)  \n","27      J. Phys. Soc. Jpn. 87, 023704 (2018)  \n","34                                      None  \n","47  Solid State Communications 244,57 (2016)  "],"text/html":["\n","  <div id=\"df-0aec4ba2-3458-45e6-a957-23b4e860dd55\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>arxiv_id</th>\n","      <th>entry_id</th>\n","      <th>doi</th>\n","      <th>title</th>\n","      <th>abstract</th>\n","      <th>authors</th>\n","      <th>authors_str</th>\n","      <th>published</th>\n","      <th>updated</th>\n","      <th>year</th>\n","      <th>primary_category</th>\n","      <th>categories</th>\n","      <th>pdf_url</th>\n","      <th>comment</th>\n","      <th>journal_ref</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>17</th>\n","      <td>2001.07928v1</td>\n","      <td>http://arxiv.org/abs/2001.07928v1</td>\n","      <td>10.7566/JPSJ.89.064702</td>\n","      <td>Bulk superconductivity induced by Se substitut...</td>\n","      <td>We report the Se substitution effects on the c...</td>\n","      <td>[Ryosuke Kiyama, Yosuke Goto, Kazuhisa Hoshi, ...</td>\n","      <td>Ryosuke Kiyama, Yosuke Goto, Kazuhisa Hoshi, R...</td>\n","      <td>2020-01-22T09:35:42+00:00</td>\n","      <td>2020-01-22T09:35:42+00:00</td>\n","      <td>2020</td>\n","      <td>cond-mat.supr-con</td>\n","      <td>[cond-mat.supr-con, cond-mat.mtrl-sci]</td>\n","      <td>https://arxiv.org/pdf/2001.07928v1</td>\n","      <td>15 pages, 8 figures</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>1810.08404v3</td>\n","      <td>http://arxiv.org/abs/1810.08404v3</td>\n","      <td>None</td>\n","      <td>Bulk superconductivity in La2O2M4S6-type layer...</td>\n","      <td>Recently, we reported the observation of super...</td>\n","      <td>[Rajveer Jha, Yosuke Goto, Tatsuma D. Matsuda,...</td>\n","      <td>Rajveer Jha, Yosuke Goto, Tatsuma D. Matsuda, ...</td>\n","      <td>2018-10-19T08:55:02+00:00</td>\n","      <td>2019-04-15T07:46:09+00:00</td>\n","      <td>2018</td>\n","      <td>cond-mat.supr-con</td>\n","      <td>[cond-mat.supr-con]</td>\n","      <td>https://arxiv.org/pdf/1810.08404v3</td>\n","      <td>18 Pages, 8 figures. The title has been change...</td>\n","      <td>Scientific Reports 9, 13346 (2019)</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>1712.06815v1</td>\n","      <td>http://arxiv.org/abs/1712.06815v1</td>\n","      <td>10.7566/JPSJ.87.023704</td>\n","      <td>Evolution of Anisotropic Displacement Paramete...</td>\n","      <td>In order to understand the mechanisms behind t...</td>\n","      <td>[Yoshikazu Mizuguchi, Kazuhisa Hoshi, Yosuke G...</td>\n","      <td>Yoshikazu Mizuguchi, Kazuhisa Hoshi, Yosuke Go...</td>\n","      <td>2017-12-19T08:25:07+00:00</td>\n","      <td>2017-12-19T08:25:07+00:00</td>\n","      <td>2017</td>\n","      <td>cond-mat.supr-con</td>\n","      <td>[cond-mat.supr-con, cond-mat.mtrl-sci]</td>\n","      <td>https://arxiv.org/pdf/1712.06815v1</td>\n","      <td>None</td>\n","      <td>J. Phys. Soc. Jpn. 87, 023704 (2018)</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>1701.07575v1</td>\n","      <td>http://arxiv.org/abs/1701.07575v1</td>\n","      <td>10.1088/1742-6596/871/1/012007</td>\n","      <td>Synchrotron powder X-ray diffraction and struc...</td>\n","      <td>Eu0.5La0.5FBiS2-xSex is a new BiS2-based super...</td>\n","      <td>[K. Nagasaka, G. Jinno, O. Miura, A. Miura, C....</td>\n","      <td>K. Nagasaka, G. Jinno, O. Miura, A. Miura, C. ...</td>\n","      <td>2017-01-26T04:36:20+00:00</td>\n","      <td>2017-01-26T04:36:20+00:00</td>\n","      <td>2017</td>\n","      <td>cond-mat.supr-con</td>\n","      <td>[cond-mat.supr-con]</td>\n","      <td>https://arxiv.org/pdf/1701.07575v1</td>\n","      <td>5 pages, 2 figures, to appear in proceedings o...</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>1508.04820v1</td>\n","      <td>http://arxiv.org/abs/1508.04820v1</td>\n","      <td>10.1016/j.ssc.2016.07.001</td>\n","      <td>Applying experimental constraints to a one-dim...</td>\n","      <td>Recent ARPES measurements [Phys. Rev. B 92, 04...</td>\n","      <td>[M. A. Griffith, K. Foyevtsova, M. A. Continen...</td>\n","      <td>M. A. Griffith, K. Foyevtsova, M. A. Continent...</td>\n","      <td>2015-08-19T22:39:35+00:00</td>\n","      <td>2015-08-19T22:39:35+00:00</td>\n","      <td>2015</td>\n","      <td>cond-mat.supr-con</td>\n","      <td>[cond-mat.supr-con, cond-mat.str-el]</td>\n","      <td>https://arxiv.org/pdf/1508.04820v1</td>\n","      <td>4pages+references+supplemental material</td>\n","      <td>Solid State Communications 244,57 (2016)</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0aec4ba2-3458-45e6-a957-23b4e860dd55')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-0aec4ba2-3458-45e6-a957-23b4e860dd55 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-0aec4ba2-3458-45e6-a957-23b4e860dd55');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"sample_df","repr_error":"0"}},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["## 2.5 Creating a Test Subset (Optional)\n","To test our download pipeline without processing the entire corpus, we generate a small, reproducible random sample. This allows us to debug connection issues or file handling logic quickly before committing to the full dataset.\n","\n","* **Sample Size:** Defined by `NUM_PAPERS`.\n","* **Reproducibility:** Controlled by `RANDOM_SEED` to ensure we test on the same papers every time we run this cell."],"metadata":{"id":"OgNEPpl2nDjx"}},{"cell_type":"code","source":["# --- Configuration ---\n","NUM_PAPERS = 10\n","RANDOM_SEED = 42\n","\n","# --- Create Sample ---\n","# We sample directly from the full dataframe loaded in the previous step\n","test_corpus = df_corpus.sample(n=NUM_PAPERS, random_state=RANDOM_SEED)\n","\n","print(\"\\n\" + \"=\"*40)\n","print(f\"üß™ Test Corpus Generated\")\n","print(\"=\"*40)\n","print(f\"Size: {len(test_corpus)} papers\")\n","print(f\"Seed: {RANDOM_SEED}\")\n","\n","# Display the sample arXiv IDs to verify variety\n","print(f\"Sample IDs: {test_corpus['arxiv_id'].tolist()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sfIork8GFQ3t","executionInfo":{"status":"ok","timestamp":1769688262715,"user_tz":-60,"elapsed":15,"user":{"displayName":"Dar√≠o Santos","userId":"05949316178413510452"}},"outputId":"903f95a7-eb97-49c1-b6a9-0be119a255ef"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","========================================\n","üß™ Test Corpus Generated\n","========================================\n","Size: 10 papers\n","Seed: 42\n","Sample IDs: ['1411.6903v1', '1603.02819v1', '1911.02337v1', '1708.03840v1', '1310.1213v2', '1410.6775v2', '1402.1833v1', '1909.01710v1', '1308.1072v3', '1801.06568v1']\n"]}]},{"cell_type":"markdown","source":["# 3 . Core Logic: PDF Download Function\n","We define a robust function to handle the retrieval of PDF files. This function is designed with several safeguards to ensure data integrity and respect server limits:\n","\n","1.  **URL Normalization:** Automatically converts arXiv abstract URLs (`/abs/`) to direct PDF links (`/pdf/`).\n","2.  **Idempotency:** Checks if the file already exists locally to prevent redundant downloads and save bandwidth.\n","3.  **Resilience:** Implements a retry mechanism (backoff) to handle network timeouts or temporary server errors.\n","4.  **Integrity:** Calculates an MD5 checksum of the downloaded content to verify that the file is not corrupted.\n","5.  **Dynamic Storage:** Accepts a target directory argument, allowing us to easily switch between saving to the \"Sample\" folder or the \"Full Corpus\" folder."],"metadata":{"id":"ooaBcDD8Nq3M"}},{"cell_type":"code","source":["def download_pdf(\n","    arxiv_id: str,\n","    pdf_url: str,\n","    save_directory: Path = CorpusConfig.PDF_DIR\n",") -> tuple[str, Optional[Path]]: # Changed return type\n","    \"\"\"\n","    Download a single PDF and save it with the ArXiv ID as the filename.\n","\n","    Args:\n","        arxiv_id (str): ArXiv identifier (e.g., \"2301.12345\").\n","        pdf_url (str): The URL to the PDF resource.\n","        save_directory (Path): The folder where the PDF should be saved.\n","                               Defaults to the main PDF corpus directory.\n","\n","    Returns:\n","        tuple[str, Optional[Path]]: A tuple containing a status string ('downloaded', 'skipped', 'failed')\n","                                     and the path to the saved PDF, or None if the download failed.\n","    \"\"\"\n","    # --- 1. Normalize URL ---\n","    # Ensure we are targeting the PDF binary, not the abstract HTML page\n","    if \"arxiv.org/abs/\" in pdf_url:\n","        pdf_url = pdf_url.replace(\"/abs/\", \"/pdf/\")\n","    if not pdf_url.endswith(\".pdf\"):\n","        pdf_url += \".pdf\"\n","\n","    # --- 2. Define Target Path ---\n","    pdf_path = save_directory / f\"{arxiv_id}.pdf\"\n","\n","    # --- 3. Check for Existing File ---\n","    if pdf_path.exists():\n","        logging.info(f\"‚è≠Ô∏è  Skipped (Exists): {arxiv_id}\")\n","        return \"skipped\", pdf_path # Return 'skipped' status\n","\n","    # --- 4. Download Execution ---\n","    # User-Agent is set to indicate academic research and avoid being blocked as a generic bot\n","    headers = {'User-Agent': 'Mozilla/5.0 (Academic Research; BiS2-Project)'}\n","\n","    for attempt in range(CorpusConfig.MAX_RETRIES):\n","        try:\n","            response = requests.get(\n","                pdf_url,\n","                headers=headers,\n","                timeout=CorpusConfig.TIMEOUT\n","            )\n","\n","            if response.status_code == 200:\n","                # Save binary content to disk\n","                with open(pdf_path, 'wb') as f:\n","                    f.write(response.content)\n","\n","                # Calculate checksum for integrity verification\n","                checksum = hashlib.md5(response.content).hexdigest()\n","                logging.info(f\"‚¨áÔ∏è  Downloaded: {arxiv_id} (MD5: {checksum[:8]})\")\n","\n","                return \"downloaded\", pdf_path # Return 'downloaded' status\n","\n","            elif response.status_code == 404:\n","                logging.warning(f\"‚ùå PDF not found (404): {arxiv_id}\")\n","                return \"failed\", None # Return 'failed' status\n","\n","            else:\n","                logging.warning(f\"‚ö†Ô∏è  Status {response.status_code} for {arxiv_id}\")\n","\n","        except Exception as e:\n","            logging.warning(f\"‚ö†Ô∏è  Attempt {attempt+1} failed for {arxiv_id}: {e}\")\n","            if attempt < CorpusConfig.MAX_RETRIES - 1:\n","                time.sleep(CorpusConfig.RETRY_DELAY)\n","\n","    logging.error(f\"‚ùå Failed to download {arxiv_id} after {CorpusConfig.MAX_RETRIES} attempts\")\n","    return \"failed\", None # Return 'failed' status"],"metadata":{"id":"EHqxIKl84Vqn","executionInfo":{"status":"ok","timestamp":1769689361469,"user_tz":-60,"elapsed":18,"user":{"displayName":"Dar√≠o Santos","userId":"05949316178413510452"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["## 3.1 Batch Processing and Manifest Generation\n","We now implement the higher-level logic to process the entire DataFrame.\n","\n","### `build_local_corpus`\n","This function iterates through the list of papers and triggers the download for each. It tracks success/failure statistics to provide a summary report.\n","\n","### `save_corpus_manifest`\n","Crucially, we generate a **Manifest File (`.json`)** alongside the PDF downloads. This manifest serves as a snapshot of the local dataset, recording:\n","* Which files were successfully downloaded.\n","* File sizes and MD5 checksums (for verifying data integrity later).\n","* The relative path to each file."],"metadata":{"id":"ExOCqiLLn9eQ"}},{"cell_type":"code","source":["def save_corpus_manifest(\n","    metadata_df: pd.DataFrame,\n","    download_stats: Dict,\n","    save_directory: Path,\n","    filename: str = \"corpus_manifest.json\"\n","):\n","    \"\"\"\n","    Create a detailed JSON manifest documenting the downloaded corpus.\n","    This ensures we have a snapshot of exactly what files exist locally.\n","    \"\"\"\n","\n","    manifest = {\n","        \"corpus_version\": CorpusConfig.CORPUS_VERSION,\n","        \"creation_date\": CorpusConfig.CREATION_DATE,\n","        \"total_papers\": len(metadata_df),\n","        \"download_stats\": download_stats,\n","        \"papers\": []\n","    }\n","\n","    print(f\"üìù Generating manifest in: {save_directory.name}...\")\n","\n","    for idx, row in metadata_df.iterrows():\n","        arxiv_id = row['arxiv_id']\n","        pdf_path = save_directory / f\"{arxiv_id}.pdf\"\n","\n","        paper_info = {\n","            \"arxiv_id\": arxiv_id,\n","            \"title\": row.get('title', 'Unknown'),\n","            \"published\": row.get('published', 'Unknown'),\n","            \"pdf_url\": row['pdf_url'],\n","            # Store path relative to project root for portability\n","            \"local_path\": str(pdf_path.relative_to(CorpusConfig.BASE_DIR)) if pdf_path.exists() else None,\n","            \"file_exists\": pdf_path.exists()\n","        }\n","\n","        if pdf_path.exists():\n","            # Add file metadata\n","            paper_info[\"file_size_kb\"] = round(pdf_path.stat().st_size / 1024, 2)\n","            try:\n","                with open(pdf_path, 'rb') as f:\n","                    paper_info[\"md5_checksum\"] = hashlib.md5(f.read()).hexdigest()\n","            except Exception as e:\n","                paper_info[\"md5_checksum\"] = \"error_reading_file\"\n","\n","        manifest[\"papers\"].append(paper_info)\n","\n","    # Save manifest to the same directory as the PDFs\n","    manifest_path = save_directory / filename\n","    with open(manifest_path, 'w', encoding='utf-8') as f:\n","        json.dump(manifest, f, indent=2)\n","\n","    logging.info(f\"Manifest saved: {manifest_path}\")\n","    print(f\"‚úÖ Manifest saved: {manifest_path}\")\n","\n","\n","def build_local_corpus(\n","    metadata_df: pd.DataFrame,\n","    save_directory: Path = CorpusConfig.PDF_DIR,\n","    manifest_filename: str = \"corpus_manifest.json\"\n",") -> Dict:\n","    \"\"\"\n","    Orchestrate the download of all PDFs in the metadata DataFrame.\n","\n","    Args:\n","        metadata_df: DataFrame containing 'arxiv_id' and 'pdf_url'.\n","        save_directory: Target folder for PDFs (Sample or Full).\n","        manifest_filename: Name for the summary JSON file.\n","\n","    Returns:\n","        Dictionary containing execution statistics.\n","    \"\"\"\n","    stats = {\n","        \"total\": len(metadata_df),\n","        \"success\": 0,\n","        \"failed\": 0,\n","        \"already_existed\": 0, # Added for clarity\n","        \"failed_ids\": []\n","    }\n","\n","    logging.info(f\"Starting download for {len(metadata_df)} papers into {save_directory.name}\")\n","    print(f\"\\n{'='*60}\")\n","    print(f\"üöÄ STARTING CORPUS BUILD\")\n","    print(f\"Target Directory: {save_directory}\")\n","    print(f\"{'-'*60}\") # Changed from '=' for visual distinction\n","    print(f\"Total papers to process: {stats['total']}\") # Added for clarity\n","    print(f\"{'-'*60}\\n\") # Changed from '=' for visual distinction\n","\n","    for idx, row in metadata_df.iterrows():\n","        arxiv_id = row['arxiv_id']\n","\n","        # Pass the dynamic save_directory to the download function\n","        download_status, result_path = download_pdf(arxiv_id, row['pdf_url'], save_directory=save_directory) # Unpack status\n","\n","        # Update Statistics based on status\n","        if download_status == \"downloaded\":\n","            stats[\"success\"] += 1\n","        elif download_status == \"skipped\":\n","            stats[\"success\"] += 1 # Count as success as the file is available\n","            stats[\"already_existed\"] += 1 # Increment 'already_existed'\n","        else: # download_status == \"failed\"\n","            stats[\"failed\"] += 1\n","            stats[\"failed_ids\"].append(arxiv_id)\n","\n","        # Progress update every 10 papers\n","        if (idx + 1) % 10 == 0 or (idx + 1) == len(metadata_df): # Added (idx+1)==len(metadata_df) to ensure final update\n","            print(f\"‚è≥ Progress: {idx+1}/{len(metadata_df)}... (Downloaded: {stats['success'] - stats['already_existed']}, Skipped: {stats['already_existed']}, Failed: {stats['failed']})\") # Detailed progress\n","\n","        # Rate Limiting: Be polite to ArXiv\n","        time.sleep(1)\n","\n","    # --- Summary ---\n","    print(f\"\\n{'='*60}\")\n","    print(\"üèÅ DOWNLOAD COMPLETE\")\n","    print(f\"{'-'*60}\") # Changed from '=' for visual distinction\n","    print(f\"Total processed: {stats['total']}\")\n","    print(f\"Successfully retrieved (new downloads + existing): {stats['success']} ({(stats['success']/stats['total'])*100:.1f}%) -- New Downloads: {stats['success'] - stats['already_existed']}, Skipped (Already Existed): {stats['already_existed']}\") # Detailed success breakdown\n","    print(f\"Failed:  {stats['failed']}\")\n","\n","    if stats['failed_ids']:\n","        print(f\"‚ö†Ô∏è Failed IDs: {stats['failed_ids']}\")\n","\n","    # --- Generate Manifest ---\n","    save_corpus_manifest(metadata_df, stats, save_directory, manifest_filename)\n","\n","    return stats"],"metadata":{"id":"ObSBOUno5Vl8","executionInfo":{"status":"ok","timestamp":1769689361835,"user_tz":-60,"elapsed":27,"user":{"displayName":"Dar√≠o Santos","userId":"05949316178413510452"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["## 3.2 Execution: Downloading the Sample Corpus\n","We first run the pipeline on the `test_corpus` (10 papers). This verifies that:\n","1.  The connection to arXiv is working.\n","2.  PDFs are saving correctly to the `sample_pdfs` folder.\n","3.  The manifest JSON is generated accurately."],"metadata":{"id":"tuwxN9GzoYQJ"}},{"cell_type":"code","source":["# --- Run Pipeline on Sample ---\n","sample_stats = build_local_corpus(\n","    metadata_df=test_corpus,\n","    save_directory=CorpusConfig.SAMPLE_PDF_DIR,\n","    manifest_filename=\"sample_corpus_manifest.json\"\n",")\n","\n","# --- Verification ---\n","# List the files in the sample directory to confirm\n","print(f\"\\nüìÇ Contents of {CorpusConfig.SAMPLE_PDF_DIR.name}:\")\n","for f in list(CorpusConfig.SAMPLE_PDF_DIR.glob(\"*.pdf\"))[:5]:  # Show first 5\n","    print(f\" - {f.name} ({round(f.stat().st_size / 1024)} KB)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HcrEMuRm594O","executionInfo":{"status":"ok","timestamp":1769689425813,"user_tz":-60,"elapsed":10156,"user":{"displayName":"Dar√≠o Santos","userId":"05949316178413510452"}},"outputId":"bc131847-258d-46e0-d431-419d5a9fd806"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","üöÄ STARTING CORPUS BUILD\n","Target Directory: /content/drive/My Drive/TFM/data/raw/pdfs/sample_pdfs\n","------------------------------------------------------------\n","Total papers to process: 10\n","------------------------------------------------------------\n","\n","‚è≥ Progress: 20/10... (Downloaded: 0, Skipped: 3, Failed: 0)\n","‚è≥ Progress: 70/10... (Downloaded: 0, Skipped: 7, Failed: 0)\n","\n","============================================================\n","üèÅ DOWNLOAD COMPLETE\n","------------------------------------------------------------\n","Total processed: 10\n","Successfully retrieved (new downloads + existing): 10 (100.0%) -- New Downloads: 0, Skipped (Already Existed): 10\n","Failed:  0\n","üìù Generating manifest in: sample_pdfs...\n","‚úÖ Manifest saved: /content/drive/My Drive/TFM/data/raw/pdfs/sample_pdfs/sample_corpus_manifest.json\n","\n","üìÇ Contents of sample_pdfs:\n"," - 1411.6903v1.pdf (602 KB)\n"," - 1603.02819v1.pdf (267 KB)\n"," - 1911.02337v1.pdf (829 KB)\n"," - 1708.03840v1.pdf (1497 KB)\n"," - 1310.1213v2.pdf (289 KB)\n"]}]},{"cell_type":"markdown","source":["## 3.3 Preparation for Full Corpus Download\n","Before executing the download on the entire dataset, we define a flexible loading utility. This function ensures we can ingest metadata from either JSON or CSV formats and performs a critical check on the `pdf_url` column to identify missing links.\n","\n","* **Robustness:** Handles different file extensions automatically.\n","* **Validation:** Checks for missing PDF URLs, which would cause the download loop to fail."],"metadata":{"id":"L5DFHshIqFDX"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"090166f2","executionInfo":{"status":"ok","timestamp":1768391286115,"user_tz":-60,"elapsed":36,"user":{"displayName":"Dar√≠o Santos","userId":"05949316178413510452"}},"outputId":"0f19a415-8e3d-4a1b-c947-55bef929623c"},"source":["# Assuming your JSON file is corpus_manifest.json as created previously\n","\n","json_file_path = Path(\"/content/drive/MyDrive/TFM/data/raw/pdfs/corpus_v1.0_pdfs/corpus_manifest.json\")\n","\n","if json_file_path.exists():\n","    with open(json_file_path, 'r') as f:\n","        json_data = json.load(f)\n","\n","    print(f\"Loaded JSON file: {json_file_path}\")\n","    print(f\"Top-level type: {type(json_data)}\")\n","\n","    if isinstance(json_data, list):\n","        print(f\"Number of items in the list: {len(json_data)}\")\n","    elif isinstance(json_data, dict):\n","        print(f\"Number of top-level keys: {len(json_data.keys())}\")\n","        print(f\"Top-level keys: {list(json_data.keys())}\")\n","\n","    # Optionally, display a part of the data to see its structure\n","    # For large files, print only a small sample\n","    print(\"\\nFirst few items/keys and their values (truncated if large):\")\n","    if isinstance(json_data, list):\n","        for i, item in enumerate(json_data[:2]): # Display first 2 items\n","            print(f\"Item {i}: {json.dumps(item, indent=2)[:500]}...\") # Truncate output\n","    elif isinstance(json_data, dict):\n","        for key, value in list(json_data.items()): # Display first 3 key-value pairs\n","            print(f\"Key '{key}': {json.dumps(value, indent=2)[:500]}...\") # Truncate output\n","\n","else:\n","    print(f\"Error: JSON file not found at {json_file_path}\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded JSON file: /content/drive/MyDrive/TFM/data/raw/pdfs/corpus_v1.0_pdfs/corpus_manifest.json\n","Top-level type: <class 'dict'>\n","Number of top-level keys: 5\n","Top-level keys: ['corpus_version', 'creation_date', 'total_papers', 'download_stats', 'papers']\n","\n","First few items/keys and their values (truncated if large):\n","Key 'corpus_version': \"v1.0\"...\n","Key 'creation_date': \"2026-01-14\"...\n","Key 'total_papers': 130...\n","Key 'download_stats': {\n","  \"total\": 130,\n","  \"success\": 130,\n","  \"failed\": 0,\n","  \"already_existed\": 130,\n","  \"failed_ids\": []\n","}...\n","Key 'papers': [\n","  {\n","    \"arxiv_id\": \"2406.01263v2\",\n","    \"title\": \"Pb Substitution Effects on Lattice and Electronic System of the BiS2-based Superconductors La(O F)BiS2\",\n","    \"published\": \"2024-06-03T12:24:51+00:00\",\n","    \"pdf_url\": \"https://arxiv.org/pdf/2406.01263v2\",\n","    \"local_path\": \"data/raw/pdfs/corpus_v1.0_pdfs/2406.01263v2.pdf\",\n","    \"file_exists\": true,\n","    \"file_size_kb\": 3881.12890625,\n","    \"md5_checksum\": \"308efa46a8624aba94793d0bdf23f2d1\"\n","  },\n","  {\n","    \"arxiv_id\": \"2405.09129v2\",\n","    \"title\": \"Aging...\n"]}]},{"cell_type":"markdown","source":["## 3.4 Text Extraction Logic\n","Now that we have the PDF files, we need to extract the raw text content to build our NLP dataset. We use `fitz` (PyMuPDF) to iterate through the pages of each PDF.\n","\n","We define two functions:\n","1.  **`extract_text_from_pdf`**: A pure function that takes a specific PDF file and saves the text to a target folder. It also calculates metadata (word count, page count).\n","2.  **`batch_extract_texts`**: A wrapper that iterates through a source directory (e.g., `sample_pdfs` or `corpus_pdfs`) and triggers the extraction for every file found."],"metadata":{"id":"ZQPkfCvXrCj9"}},{"cell_type":"code","source":["def extract_text_from_pdf(\n","    pdf_path: Path,\n","    output_dir: Path\n",") -> Dict:\n","    \"\"\"\n","    Extract full text from a specific local PDF file using PyMuPDF.\n","\n","    Args:\n","        pdf_path: Path object pointing to the source PDF.\n","        output_dir: Path object pointing to where the .txt file should be saved.\n","\n","    Returns:\n","        Dict containing metadata (word count, extraction status, etc.)\n","    \"\"\"\n","    arxiv_id = pdf_path.stem  # Extract filename without extension (e.g., '2301.12345')\n","    text_filename = f\"{arxiv_id}_full.txt\"\n","    output_path = output_dir / text_filename\n","\n","    metadata = {\n","        \"arxiv_id\": arxiv_id,\n","        \"page_count\": 0,\n","        \"word_count\": 0,\n","        \"char_count\": 0,\n","        \"extraction_method\": \"pymupdf\",\n","        \"source_file\": pdf_path.name,\n","        \"error\": None\n","    }\n","\n","    # --- Check for existing text file ---\n","    if output_path.exists():\n","        logging.info(f\"‚è≠Ô∏è  Skipped text extraction (Exists): {arxiv_id}\")\n","        # Optionally, you could try to load existing metadata here if needed.\n","        # For simplicity, we just mark it as skipped and return basic info.\n","        metadata[\"status\"] = \"skipped_existing\"\n","        metadata[\"char_count\"] = output_path.stat().st_size # Approximate size without reading file\n","        try:\n","            with open(output_path, 'r', encoding='utf-8') as f:\n","                content = f.read()\n","                metadata[\"word_count\"] = len(content.split())\n","        except Exception: # Handle potential issues reading the file just for word count\n","            metadata[\"word_count\"] = 0\n","        return metadata\n","\n","    try:\n","        # Open PDF\n","        with fitz.open(pdf_path) as doc:\n","            metadata[\"page_count\"] = len(doc)\n","            full_text = \"\"\n","\n","            # Iterate pages\n","            for page in doc:\n","                # Get text blocks\n","                full_text += page.get_text() + \"\\n\\n\"\n","\n","        # Update metadata\n","        metadata[\"char_count\"] = len(full_text)\n","        metadata[\"word_count\"] = len(full_text.split())\n","        metadata[\"status\"] = \"extracted\"\n","\n","        # Save Text to Disk\n","        with open(output_path, 'w', encoding='utf-8') as f:\n","            f.write(full_text)\n","\n","        logging.info(f\"‚úÖ Extracted: {arxiv_id} ({metadata['word_count']} words)\")\n","\n","    except Exception as e:\n","        logging.error(f\"‚ùå Error extracting {arxiv_id}: {e}\")\n","        metadata[\"error\"] = str(e)\n","        metadata[\"status\"] = \"failed_extraction\"\n","\n","    return metadata\n","\n","\n","def batch_extract_texts(\n","    source_pdf_dir: Path,\n","    target_text_dir: Path\n",") -> List[Dict]:\n","    \"\"\"\n","    Iterate through all PDFs in the source directory and extract text.\n","\n","    Args:\n","        source_pdf_dir: Directory containing .pdf files.\n","        target_text_dir: Directory where .txt files will be saved.\n","\n","    Returns:\n","        List of dictionaries containing extraction metadata for the processed batch.\n","    \"\"\"\n","    # Ensure target directory exists\n","    target_text_dir.mkdir(parents=True, exist_ok=True)\n","\n","    # Find all PDFs\n","    pdf_files = list(source_pdf_dir.glob(\"*.pdf\"))\n","\n","    print(f\"\\n{'='*60}\")\n","    print(f\"üìÑ STARTING TEXT EXTRACTION\")\n","    print(f\"Source: {source_pdf_dir.name}\")\n","    print(f\"Target: {target_text_dir.name}\")\n","    print(f\"Files to process: {len(pdf_files)}\")\n","    print(f\"{'-'*60}\\n\") # Changed from '=' for visual distinction\n","\n","    results = []\n","\n","    for i, pdf_path in enumerate(pdf_files):\n","        # Execute Extraction\n","        meta = extract_text_from_pdf(pdf_path, target_text_dir)\n","        results.append(meta)\n","\n","        # Progress logging\n","        if (i + 1) % 10 == 0 or (i + 1) == len(pdf_files):\n","            # Count actual extractions vs. skipped ones for clearer progress\n","            extracted_count = sum(1 for r in results if r.get('status') == 'extracted')\n","            skipped_count = sum(1 for r in results if r.get('status') == 'skipped_existing')\n","            failed_count = sum(1 for r in results if r.get('status') == 'failed_extraction')\n","\n","            print(f\"[{datetime.now().strftime('%H:%M:%S')}] Processed {i+1}/{len(pdf_files)}... (Extracted: {extracted_count}, Skipped: {skipped_count}, Failed: {failed_count})\")\n","\n","    print(f\"\\n‚úÖ Extraction Complete!\")\n","    return results"],"metadata":{"id":"x1ZcZuP876Hp","executionInfo":{"status":"ok","timestamp":1769689838885,"user_tz":-60,"elapsed":22,"user":{"displayName":"Dar√≠o Santos","userId":"05949316178413510452"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["## 3.5 Execution: Extracting Text from Sample PDFs\n","We run the extraction pipeline on our downloaded **sample PDFs**.\n","This serves as a quality check:\n","1.  Verify that `fitz` can open the downloaded files (checking for corruption).\n","2.  Inspect the resulting `.txt` files to ensure character encoding (UTF-8) is correct."],"metadata":{"id":"VKf-aIX2rb9c"}},{"cell_type":"code","source":["# --- Run Extraction on Sample ---\n","sample_extraction_results = batch_extract_texts(\n","    source_pdf_dir=CorpusConfig.SAMPLE_PDF_DIR,\n","    target_text_dir=CorpusConfig.SAMPLE_TEXT_DIR\n",")\n","\n","# --- Verification ---\n","# Display the first few results to check word counts\n","print(\"\\nüîç Sample Extraction Stats:\")\n","df_sample_stats = pd.DataFrame(sample_extraction_results)\n","# Using standard pandas display for clearer table formatting\n","display(df_sample_stats[['arxiv_id', 'word_count', 'error', 'status']].head(10))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":589},"id":"2728aVJE-yc9","executionInfo":{"status":"ok","timestamp":1769689652695,"user_tz":-60,"elapsed":123,"user":{"displayName":"Dar√≠o Santos","userId":"05949316178413510452"}},"outputId":"e37fd774-c747-4ba0-b94d-146efc7c9f8e"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","üìÑ STARTING TEXT EXTRACTION\n","Source: sample_pdfs\n","Target: sample_text_dumps\n","Files to process: 10\n","------------------------------------------------------------\n","\n","[12:27:32] Processed 10/10... (Extracted: 0, Skipped: 10, Failed: 0)\n","\n","‚úÖ Extraction Complete!\n","\n","üîç Sample Extraction Stats:\n"]},{"output_type":"display_data","data":{"text/plain":["       arxiv_id  word_count error            status\n","0   1411.6903v1        7408  None  skipped_existing\n","1  1603.02819v1        9531  None  skipped_existing\n","2  1911.02337v1        3149  None  skipped_existing\n","3  1708.03840v1        3790  None  skipped_existing\n","4   1310.1213v2        2554  None  skipped_existing\n","5   1410.6775v2        2955  None  skipped_existing\n","6   1402.1833v1        4196  None  skipped_existing\n","7  1909.01710v1        4379  None  skipped_existing\n","8   1308.1072v3        4676  None  skipped_existing\n","9  1801.06568v1        4446  None  skipped_existing"],"text/html":["\n","  <div id=\"df-d970ffcc-de27-45a8-8715-9fcc0456c2eb\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>arxiv_id</th>\n","      <th>word_count</th>\n","      <th>error</th>\n","      <th>status</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1411.6903v1</td>\n","      <td>7408</td>\n","      <td>None</td>\n","      <td>skipped_existing</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1603.02819v1</td>\n","      <td>9531</td>\n","      <td>None</td>\n","      <td>skipped_existing</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1911.02337v1</td>\n","      <td>3149</td>\n","      <td>None</td>\n","      <td>skipped_existing</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1708.03840v1</td>\n","      <td>3790</td>\n","      <td>None</td>\n","      <td>skipped_existing</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1310.1213v2</td>\n","      <td>2554</td>\n","      <td>None</td>\n","      <td>skipped_existing</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1410.6775v2</td>\n","      <td>2955</td>\n","      <td>None</td>\n","      <td>skipped_existing</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1402.1833v1</td>\n","      <td>4196</td>\n","      <td>None</td>\n","      <td>skipped_existing</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1909.01710v1</td>\n","      <td>4379</td>\n","      <td>None</td>\n","      <td>skipped_existing</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1308.1072v3</td>\n","      <td>4676</td>\n","      <td>None</td>\n","      <td>skipped_existing</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1801.06568v1</td>\n","      <td>4446</td>\n","      <td>None</td>\n","      <td>skipped_existing</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d970ffcc-de27-45a8-8715-9fcc0456c2eb')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d970ffcc-de27-45a8-8715-9fcc0456c2eb button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d970ffcc-de27-45a8-8715-9fcc0456c2eb');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","repr_error":"Out of range float values are not JSON compliant: nan"}},"metadata":{}}]},{"cell_type":"markdown","source":["# 4 . Execution"],"metadata":{"id":"o8lWkh-Tr2SV"}},{"cell_type":"markdown","source":["## 4.1 Full Corpus Download\n","**‚ö†Ô∏è Warning: Long-Running Process**\n","This cell triggers the download for the entire dataset (`corpus_df`). Depending on the number of papers and the `time.sleep` interval (politeness policy), this may take a significant amount of time.\n","\n","* **Input:** `corpus_df` (Metadata from Notebook 1)\n","* **Output:** PDFs saved to `data/raw/pdfs/corpus_vX.X_pdfs`\n","* **Manifest:** A `corpus_manifest.json` will be generated in the same folder."],"metadata":{"id":"Og0G9kuGsQdB"}},{"cell_type":"code","source":["# --- 1. Execute Full Download ---\n","# We pass the main configuration directory for the full corpus\n","full_download_stats = build_local_corpus(\n","    metadata_df=corpus_df,\n","    save_directory=CorpusConfig.PDF_DIR,\n","    manifest_filename=\"corpus_manifest.json\"\n",")\n","\n","# --- 2. Save Statistics for Reference ---\n","# It's good practice to save the run statistics to a log file\n","log_path = CorpusConfig.LOG_DIR / f\"download_stats_{datetime.now().strftime('%Y%m%d')}.json\"\n","with open(log_path, 'w') as f:\n","    json.dump(full_download_stats, f, indent=2)\n","\n","print(f\"\\nüìù Detailed download logs saved to: {log_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aqRsjjPZ7-7m","executionInfo":{"status":"ok","timestamp":1769689585584,"user_tz":-60,"elapsed":131605,"user":{"displayName":"Dar√≠o Santos","userId":"05949316178413510452"}},"outputId":"b5805b5d-19b6-4fd6-eaf0-d90bf0f2b328"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","üöÄ STARTING CORPUS BUILD\n","Target Directory: /content/drive/My Drive/TFM/data/raw/pdfs/corpus_v1.0_pdfs\n","------------------------------------------------------------\n","Total papers to process: 130\n","------------------------------------------------------------\n","\n","‚è≥ Progress: 10/130... (Downloaded: 0, Skipped: 10, Failed: 0)\n","‚è≥ Progress: 20/130... (Downloaded: 0, Skipped: 20, Failed: 0)\n","‚è≥ Progress: 30/130... (Downloaded: 0, Skipped: 30, Failed: 0)\n","‚è≥ Progress: 40/130... (Downloaded: 0, Skipped: 40, Failed: 0)\n","‚è≥ Progress: 50/130... (Downloaded: 0, Skipped: 50, Failed: 0)\n","‚è≥ Progress: 60/130... (Downloaded: 0, Skipped: 60, Failed: 0)\n","‚è≥ Progress: 70/130... (Downloaded: 0, Skipped: 70, Failed: 0)\n","‚è≥ Progress: 80/130... (Downloaded: 0, Skipped: 80, Failed: 0)\n","‚è≥ Progress: 90/130... (Downloaded: 0, Skipped: 90, Failed: 0)\n","‚è≥ Progress: 100/130... (Downloaded: 0, Skipped: 100, Failed: 0)\n","‚è≥ Progress: 110/130... (Downloaded: 0, Skipped: 110, Failed: 0)\n","‚è≥ Progress: 120/130... (Downloaded: 0, Skipped: 120, Failed: 0)\n","‚è≥ Progress: 130/130... (Downloaded: 0, Skipped: 130, Failed: 0)\n","\n","============================================================\n","üèÅ DOWNLOAD COMPLETE\n","------------------------------------------------------------\n","Total processed: 130\n","Successfully retrieved (new downloads + existing): 130 (100.0%) -- New Downloads: 0, Skipped (Already Existed): 130\n","Failed:  0\n","üìù Generating manifest in: corpus_v1.0_pdfs...\n","‚úÖ Manifest saved: /content/drive/My Drive/TFM/data/raw/pdfs/corpus_v1.0_pdfs/corpus_manifest.json\n","\n","üìù Detailed download logs saved to: /content/drive/My Drive/TFM/logs/download_stats_20260129.json\n"]}]},{"cell_type":"markdown","source":["## 4.2 Full Corpus Text Extraction\n","Once the PDFs are secured locally, we process them into plain text. This data will form the primary input for the NLP and Knowledge Graph construction in subsequent notebooks.\n","\n","* **Input:** PDFs from `data/raw/pdfs/corpus_vX.X_pdfs`\n","* **Output:** Text files saved to `data/processed/corpus_vX.X_text_dumps`"],"metadata":{"id":"0e4dWfljsqS0"}},{"cell_type":"code","source":["# --- 1. Execute Full Extraction ---\n","# This iterates through the directory populated in the previous step\n","full_extraction_results = batch_extract_texts(\n","    source_pdf_dir=CorpusConfig.PDF_DIR,\n","    target_text_dir=CorpusConfig.TEXT_DIR\n",")\n","\n","# --- 2. Save Extraction Metadata ---\n","# We convert the list of dictionaries (metadata) into a DataFrame and save it.\n","# This serves as an index for our text corpus (e.g., mapping arXiv IDs to word counts).\n","df_extraction_meta = pd.DataFrame(full_extraction_results)\n","\n","meta_save_path = f\"/content/drive/MyDrive/TFM/data/processed/corpus_v1.0_text_dumps/text_extraction_metadata_{CorpusConfig.CORPUS_VERSION}.csv\"\n","df_extraction_meta.to_csv(meta_save_path, index=False)\n","\n","print(f\"\\n‚úÖ Extraction metadata saved to: {meta_save_path}\")\n","print(\"üéâ Notebook 2 Complete. Data is ready for NLP processing.\")"],"metadata":{"id":"58Kof9PmFATl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1769690252192,"user_tz":-60,"elapsed":569,"user":{"displayName":"Dar√≠o Santos","userId":"05949316178413510452"}},"outputId":"59f77353-2e73-489a-d819-e6ca854f97ae"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","üìÑ STARTING TEXT EXTRACTION\n","Source: corpus_v1.0_pdfs\n","Target: corpus_v1.0_text_dumps\n","Files to process: 130\n","------------------------------------------------------------\n","\n","[12:37:31] Processed 10/130... (Extracted: 0, Skipped: 10, Failed: 0)\n","[12:37:32] Processed 20/130... (Extracted: 0, Skipped: 20, Failed: 0)\n","[12:37:32] Processed 30/130... (Extracted: 0, Skipped: 30, Failed: 0)\n","[12:37:32] Processed 40/130... (Extracted: 0, Skipped: 40, Failed: 0)\n","[12:37:32] Processed 50/130... (Extracted: 0, Skipped: 50, Failed: 0)\n","[12:37:32] Processed 60/130... (Extracted: 0, Skipped: 60, Failed: 0)\n","[12:37:32] Processed 70/130... (Extracted: 0, Skipped: 70, Failed: 0)\n","[12:37:32] Processed 80/130... (Extracted: 0, Skipped: 80, Failed: 0)\n","[12:37:32] Processed 90/130... (Extracted: 0, Skipped: 90, Failed: 0)\n","[12:37:32] Processed 100/130... (Extracted: 0, Skipped: 100, Failed: 0)\n","[12:37:32] Processed 110/130... (Extracted: 0, Skipped: 110, Failed: 0)\n","[12:37:32] Processed 120/130... (Extracted: 0, Skipped: 120, Failed: 0)\n","[12:37:32] Processed 130/130... (Extracted: 0, Skipped: 130, Failed: 0)\n","\n","‚úÖ Extraction Complete!\n","\n","‚úÖ Extraction metadata saved to: /content/drive/MyDrive/TFM/data/processed/corpus_v1.0_text_dumps/text_extraction_metadata_v1.0.csv\n","üéâ Notebook 2 Complete. Data is ready for NLP processing.\n"]}]},{"cell_type":"code","source":["# Folder size verification\n","\n","def get_folder_size(path: Path) -> tuple[int, int]:\n","    \"\"\"\n","    Calculates the total size and number of files in a given directory.\n","\n","    Args:\n","        path: The Path object of the directory.\n","\n","    Returns:\n","        A tuple containing (total_size_bytes, num_files).\n","    \"\"\"\n","    total_size = 0\n","    num_files = 0\n","    if path.exists() and path.is_dir():\n","        for file_path in path.rglob('*'):\n","            if file_path.is_file():\n","                total_size += file_path.stat().st_size\n","                num_files += 1\n","    return total_size, num_files\n","\n","def format_size(size_bytes: int) -> str:\n","    \"\"\"\n","    Formats a size in bytes to a human-readable string (KB, MB, GB).\n","    \"\"\"\n","    if size_bytes < 1024: # Bytes\n","        return f\"{size_bytes} B\"\n","    elif size_bytes < 1024**2: # Kilobytes\n","        return f\"{size_bytes / 1024:.2f} KB\"\n","    elif size_bytes < 1024**3: # Megabytes\n","        return f\"{size_bytes / (1024**2):.2f} MB\"\n","    else: # Gigabytes\n","        return f\"{size_bytes / (1024**3):.2f} GB\"\n","\n","print(\"\\n\" + \"=\"*40)\n","print(\"FOLDER SIZE VERIFICATION\")\n","print(\"=\"*40)\n","\n","# Verify main text dump folder\n","main_text_folder = CorpusConfig.TEXT_DIR\n","main_size, main_files = get_folder_size(main_text_folder)\n","print(f\"Main Text Dump Folder: {main_text_folder}\")\n","print(f\"  - Total Size: {format_size(main_size)}\")\n","print(f\"  - Number of Files: {main_files}\")\n","\n","print(\"\\n\" + \"-\"*40)\n","\n","# Verify sample text dump folder\n","sample_text_folder = CorpusConfig.SAMPLE_TEXT_DIR\n","sample_size, sample_files = get_folder_size(sample_text_folder)\n","print(f\"Sample Text Dump Folder: {sample_text_folder}\")\n","print(f\"  - Total Size: {format_size(sample_size)}\")\n","print(f\"  - Number of Files: {sample_files}\")\n","\n","print(\"\\n\" + \"=\"*40)"],"metadata":{"id":"eQeSFjhHFAQ8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768475004054,"user_tz":-60,"elapsed":302,"user":{"displayName":"Dar√≠o Santos","userId":"05949316178413510452"}},"outputId":"095d9701-4b49-4abc-cf3a-4942653cd468"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","========================================\n","FOLDER SIZE VERIFICATION\n","========================================\n","Main Text Dump Folder: /content/drive/My Drive/TFM/data/processed/corpus_v1.0_text_dumps\n","  - Total Size: 2.99 MB\n","  - Number of Files: 130\n","\n","----------------------------------------\n","Sample Text Dump Folder: /content/drive/My Drive/TFM/data/processed/sample_text_dumps\n","  - Total Size: 226.20 KB\n","  - Number of Files: 10\n","\n","========================================\n"]}]},{"cell_type":"markdown","source":["# 5 . Final Verification: Data Volume and Integrity\n","As a final step, we programmatically verify the storage footprint of our new dataset. This confirms that:\n","1.  The files were physically written to the Google Drive.\n","2.  The file counts match our expected corpus size (e.g., if we processed 100 papers, we expect ~100 text files).\n","3.  The file sizes are reasonable (e.g., if total size is 0 KB, something went wrong)."],"metadata":{"id":"pmaPORGfwstv"}},{"cell_type":"code","source":["def get_folder_stats(path: Path) -> tuple[int, int]:\n","    \"\"\"\n","    Calculates the total size and number of files in a given directory recursively.\n","\n","    Args:\n","        path: The Path object of the directory.\n","\n","    Returns:\n","        A tuple containing (total_size_bytes, num_files).\n","    \"\"\"\n","    total_size = 0\n","    num_files = 0\n","\n","    if path.exists() and path.is_dir():\n","        for file_path in path.rglob('*'):\n","            if file_path.is_file():\n","                total_size += file_path.stat().st_size\n","                num_files += 1\n","    return total_size, num_files\n","\n","def format_size(size_bytes: int) -> str:\n","    \"\"\"\n","    Formats a size in bytes to a human-readable string (KB, MB, GB).\n","    \"\"\"\n","    if size_bytes < 1024:\n","        return f\"{size_bytes} B\"\n","    elif size_bytes < 1024**2:\n","        return f\"{size_bytes / 1024:.2f} KB\"\n","    elif size_bytes < 1024**3:\n","        return f\"{size_bytes / (1024**2):.2f} MB\"\n","    else:\n","        return f\"{size_bytes / (1024**3):.2f} GB\"\n","\n","# --- Execute Verification ---\n","print(\"\\n\" + \"=\"*50)\n","print(\"üóÑÔ∏è  DATASET STORAGE VERIFICATION\")\n","print(\"=\"*50)\n","\n","# 1. Verify Main Corpus (Text)\n","main_size, main_files = get_folder_stats(CorpusConfig.TEXT_DIR)\n","print(f\"\\nüìÇ Main Text Corpus\")\n","print(f\"   Path:  {CorpusConfig.TEXT_DIR}\")\n","print(f\"   Count: {main_files} files\")\n","print(f\"   Size:  {format_size(main_size)}\")\n","\n","# 2. Verify Sample Corpus (Text)\n","sample_size, sample_files = get_folder_stats(CorpusConfig.SAMPLE_TEXT_DIR)\n","print(f\"\\nüìÇ Sample Text Corpus\")\n","print(f\"   Path:  {CorpusConfig.SAMPLE_TEXT_DIR}\")\n","print(f\"   Count: {sample_files} files\")\n","print(f\"   Size:  {format_size(sample_size)}\")\n","\n","# 3. Verify PDF Cache (Optional but useful)\n","pdf_size, pdf_files = get_folder_stats(CorpusConfig.PDF_DIR)\n","print(f\"\\nüìÇ Raw PDF Cache\")\n","print(f\"   Path:  {CorpusConfig.PDF_DIR}\")\n","print(f\"   Count: {pdf_files} files\")\n","print(f\"   Size:  {format_size(pdf_size)}\")\n","\n","print(\"\\n\" + \"=\"*50)\n","print(\"‚úÖ NOTEBOOK 2 COMPLETE\")"],"metadata":{"id":"ItQZ4yR4wybE","executionInfo":{"status":"ok","timestamp":1769690317445,"user_tz":-60,"elapsed":179,"user":{"displayName":"Dar√≠o Santos","userId":"05949316178413510452"}},"outputId":"c82411a1-15a5-4fe8-c05e-20b6c087f1a0","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","üóÑÔ∏è  DATASET STORAGE VERIFICATION\n","==================================================\n","\n","üìÇ Main Text Corpus\n","   Path:  /content/drive/My Drive/TFM/data/processed/corpus_v1.0_text_dumps\n","   Count: 131 files\n","   Size:  3.00 MB\n","\n","üìÇ Sample Text Corpus\n","   Path:  /content/drive/My Drive/TFM/data/processed/sample_text_dumps\n","   Count: 10 files\n","   Size:  280.06 KB\n","\n","üìÇ Raw PDF Cache\n","   Path:  /content/drive/My Drive/TFM/data/raw/pdfs/corpus_v1.0_pdfs\n","   Count: 131 files\n","   Size:  126.15 MB\n","\n","==================================================\n","‚úÖ NOTEBOOK 2 COMPLETE\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ULwA6XFXw0FF"},"execution_count":null,"outputs":[]}]}