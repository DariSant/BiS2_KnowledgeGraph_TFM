{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 14627311,
     "sourceType": "datasetVersion",
     "datasetId": 9343532
    }
   ],
   "dockerImageVersionId": 31260,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  },
  "colab": {
   "provenance": [
    {
     "file_id": "https://storage.googleapis.com/kaggle-colab-exported-notebooks/obraisan/tfm-notebook5-3-entityextraction-qwen-3-7b.ab10513d-2b85-4e13-a14c-f12138bb5473.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20260129/auto/storage/goog4_request&X-Goog-Date=20260129T084045Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=2a18137dfcd5d42563585feeb85f7e32e587febcd073d05fc9481311b69287401f67228d29a75a6513edc55a45fee95408f97173de924d31e33553f5c79ba6d9df7b6f26c543e7ca5925186d54d44624d617f2ea7d76fbfdd20b826775c6a952c4357fd413ee4826b839de8c39f66a8c33d50619240fbcaf855d3f9680a2ee8d1fe1a9833eee00346933394bc3b51ee0fdf7a04258cfaeac21bb57d79a3bd7ed45d778d8874c5c3b213d7e98e9d066b716c4ab3783317e1e23f3ab987f3c9164a56be6f39fd6ac35ffef2c6736703f1d67815e214fe4d4705f3d1823603d011c537f96431d5ceff8c7df6d2def94e9be77347c5d14f1d8085fd8218ae3a9d95a",
     "timestamp": 1769676050938
    }
   ],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat_minor": 0,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Notebook 5.2: Entity Extraction using Qwen 3 (8B)\n",
    "\n",
    "### Phase 5 of the Knowledge Graph Construction Pipeline\n",
    "\n",
    "## 1. Overview\n",
    "\n",
    "Following the extraction of atomic claims from the corpus (Notebook 5.1), this notebook focuses on the **Information Extraction (IE)** sub-task of **Named Entity Recognition (NER)**. Using **Qwen 3 (8B)**, we parse the unstructured text of each claim to identify and categorize domain-specific entities relevant to the study of **BiS2-based layered superconductors**.\n",
    "\n",
    "The output of this notebook serves as the nodes for our final Knowledge Graph, providing the structured \"subjects\" and \"objects\" that will be linked in the subsequent Relation Extraction phase (Notebook 5.3).\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Extraction Schema\n",
    "\n",
    "To ensure a queryable and standardized graph, the model is instructed to classify entities into the following six classes:\n",
    "\n",
    "| Entity Label | Description | Example |\n",
    "| --- | --- | --- |\n",
    "| **Material** | Specific chemical formulas (stripped of modifiers). |  |\n",
    "| **Property** | Quantitative or qualitative variables measured. | , lattice constant, resistivity |\n",
    "| **State** | High-level physical phases or macroscopic effects. | Superconductivity, CDW, Ferromagnetism |\n",
    "| **Condition** | External parameters or experimental constraints. | pressure, -substitution, magnetic field |\n",
    "| **Method** | Synthesis or characterization techniques. | XRD, DFT, Flux method, SQUID |\n",
    "| **Value** | The specific data point, including units and ranges. | , , \"high\" |\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Methodology\n",
    "\n",
    "This notebook implements a robust, academic-grade extraction workflow:\n",
    "\n",
    "1. **Model Optimization:** Loading Qwen 3 (8B) using `float16` and `bitsandbytes` for efficient GPU utilization.\n",
    "2. **Few-Shot Prompting:** Utilizing a \"Gold Standard\" subset of 6 manually annotated claims to guide the model's reasoning.\n",
    "3. **Resumable Processing:** A fault-tolerant inference loop that saves progress in real-time (`.jsonl`), protecting against runtime crashes.\n",
    "4. **Quantitative Validation:** Performance assessment using Precision, Recall, and F1-Score metrics against the Gold Standard.\n",
    "\n",
    "---\n",
    "\n",
    "**Would you like me to generate the \"Notebook 5.3: Relation Extraction\" introductory cell as well, or shall we refine the schema definitions further first?**"
   ],
   "metadata": {
    "id": "q829jrEP6X9b"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Environment Configuration\n",
    "\n",
    "To facilitate the efficient execution of the Qwen 2.5-7B/14B model on limited hardware resources, we utilize the **Hugging Face** ecosystem. The following libraries are required:\n",
    "\n",
    "* **`transformers`**: Provides the architecture and pre-trained weights for the Qwen model.\n",
    "* **`accelerate`**: Optimizes the loading of large models across available hardware (CPU/GPU) to prevent memory overflows.\n",
    "* **`bitsandbytes`**: Enables **4-bit quantization**, significantly reducing the memory footprint of the model weights without substantially compromising inference accuracy.\n",
    "\n"
   ],
   "metadata": {
    "id": "DwCy9bE_Awcu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# --- Dependency Installation ---\n",
    "# Installs the necessary libraries for quantized LLM inference.\n",
    "# -q: Quiet mode to reduce log verbosity.\n",
    "# -U: Upgrade to the latest stable versions to ensure Qwen architecture support.\n",
    "\n",
    "!pip install -q -U transformers accelerate bitsandbytes"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-26T11:13:15.828454Z",
     "iopub.execute_input": "2026-01-26T11:13:15.828667Z",
     "iopub.status.idle": "2026-01-26T11:13:33.4319Z",
     "shell.execute_reply.started": "2026-01-26T11:13:15.828645Z",
     "shell.execute_reply": "2026-01-26T11:13:33.431221Z"
    },
    "id": "myRGKdBI6X9c",
    "outputId": "5afb3dd2-4e18-46d6-c5f4-503174e267f7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1769761614802,
     "user_tz": -60,
     "elapsed": 52675,
     "user": {
      "displayName": "Dar\u00edo Santos",
      "userId": "05949316178413510452"
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m536.7/536.7 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Model Initialization\n",
    "\n",
    "We utilize **Qwen 3 (8B)** for the entity extraction task. This model was selected for its strong reasoning capabilities and adherence to complex instruction schemas.\n",
    "\n",
    "The model is loaded in half-precision (`float16`) to optimize inference speed while maintaining accuracy.\n",
    "\n"
   ],
   "metadata": {
    "id": "e6VwLAoF6X9c"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "from threading import Thread\n",
    "\n",
    "# Mount External Storage\n",
    "\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "mount_path = '/content/drive'\n",
    "\n",
    "if not os.path.exists(mount_path):\n",
    "    print(\"\ud83d\udd04 Mounting Google Drive...\")\n",
    "    drive.mount(mount_path)\n",
    "    print(\"\u2705 Google Drive mounted successfully.\")\n",
    "else:\n",
    "    print(\"\u2705 Google Drive is already mounted.\")\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    TextIteratorStreamer,\n",
    "    BitsAndBytesConfig # Imported for potential quantization\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EJDE1PyYJVWF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1769764113041,
     "user_tz": -60,
     "elapsed": 19145,
     "user": {
      "displayName": "Dar\u00edo Santos",
      "userId": "05949316178413510452"
     }
    },
    "outputId": "4a7836c6-e983-47d5-8800-3472ff95db05"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83d\udd04 Mounting Google Drive...\n",
      "Mounted at /content/drive\n",
      "\u2705 Google Drive mounted successfully.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "def initialize_model(model_id: str):\n",
    "    \"\"\"\n",
    "    Initializes the causal language model and tokenizer with optimization\n",
    "    settings for GPU inference.\n",
    "\n",
    "    Args:\n",
    "        model_id (str): The Hugging Face repository ID for the model.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the (model, tokenizer).\n",
    "    \"\"\"\n",
    "    print(f\"Loading model: {model_id}...\")\n",
    "\n",
    "    # Configuration for 4-bit quantization (Optional: Enable if VRAM is limited)\n",
    "    # bnb_config = BitsAndBytesConfig(\n",
    "    #     load_in_4bit=True,\n",
    "    #     bnb_4bit_compute_dtype=torch.float16,\n",
    "    #     bnb_4bit_use_double_quant=True,\n",
    "    # )\n",
    "\n",
    "    # Initialize Tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "\n",
    "    # Initialize Model\n",
    "    # device_map=\"auto\" distributes the model across available GPUs.\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.float16,\n",
    "        # quantization_config=bnb_config, # Uncomment to use 4-bit quantization\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "\n",
    "    print(f\"Model {model_id} loaded successfully.\")\n",
    "    return model, tokenizer\n",
    "\n",
    "# --- Configuration ---\n",
    "MODEL_ID = \"Qwen/Qwen3-8B\"\n",
    "\n",
    "# --- Execution ---\n",
    "model, tokenizer = initialize_model(MODEL_ID)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-26T13:14:20.001039Z",
     "iopub.execute_input": "2026-01-26T13:14:20.001368Z",
     "iopub.status.idle": "2026-01-26T13:15:16.013053Z",
     "shell.execute_reply.started": "2026-01-26T13:14:20.001338Z",
     "shell.execute_reply": "2026-01-26T13:15:16.012294Z"
    },
    "id": "BGEhSH5o6X9c",
    "outputId": "57e877c1-52b6-4ab5-fee0-653f3a815452",
    "colab": {
     "referenced_widgets": [
      "8b4235aa68874675b3e41e2ceef44a72",
      "ba7b7e32d0fa48c8a9f5642fcdd0e039",
      "c7cb15081e984a438c8eddeb7a160376",
      "efffee0040ee4f8c9348cca97a682473",
      "07bd113f2eb94eddbfd6a208d337be8e",
      "fbb81038f4d44755936f736c5f13c22c",
      "521831aee6e948548fef2ac9d0d5a77b",
      "5ba45d72a8904c06ae5895244a54fc4c",
      "0f3dd6a15fce41bf83a5f51737ff212c",
      "570eff5404d44c96b7e368f8cf0526b5",
      "9afe5c386aa74a7e9b5c24bb748b0650",
      "8420c0b7dc5e4330ab16be843ad7414c",
      "1bec2b85a1eb40cc80b101a0b8026f99",
      "7ec4a4727a914abf8a6565c85ca4beb2",
      "5ec688a4ecf04f0bbb8d6a315faaaaf2",
      "f1ea00fdfe1b424aa122f45f6fbe38f7",
      "cbe91aebee2642f19bba5a057df8c29e",
      "84b8d06c3839435c8870c819462f436c",
      "6322e63904e3468292abbf908973a5db",
      "842b15bab3764e119b6fe68e9f391fdf",
      "ca5b508bc78241d98be831fff412a9e8",
      "da64f592220a48e982df1ee1360658bf",
      "2ec971191511496484d30bd9b65b0771",
      "281ff381fd1d496e89566301c5ddb8a0",
      "42482ba81c644576ab17373b7bb7a7b7",
      "ea21d7f9902f410a9979908c38d228c1",
      "123be9cfc4404bce8e29403e5f9e617e",
      "5224fb99d7894bd1bc910da8345e535f",
      "192e354aa3d9442ab5c43829a0c43af7",
      "db01f33ee4b1404991616540789dbed4",
      "fd20e606ff0647128936297190dfbc46",
      "a9d5bcd402d34478aec62012e8b10dd7",
      "f495987f19304778a36363372abe1699",
      "e2bf69f1334a46a0a4388a1baf79f41b",
      "cee293436e0e4a2c89525d86de5f1774",
      "0b2702876f33435fafb25bbe17191207",
      "fa9fe424ccd2473ca458a8246fc212d2",
      "76166405b7614119b003234577f38364",
      "e8e966e1a8b74047b7a1df05caa06318",
      "01c7be62c6e44a568249188cdb15510a",
      "4de31f55926e44f8b27597d8dcf89b11",
      "e6a25ed721f44a5bb42dc6608d7afba6",
      "213334d3fca342338ed735c022ea6d7c",
      "2c3692abe4a949d68258f7a20b7dd1c1",
      "f3a9d51f4e194594aaa36ef35044119c",
      "1e3c44fbc1b34183bfb50274243c09e5",
      "343ce4e4bfa840139be3f01ea4fa4b50",
      "f76ff455ba084eb38b4de45977fe9e6d",
      "bf6b0b57730d4edd9c749e42db36d23d",
      "8b4549be1f0a4180bd2595109052cf23",
      "e5284572f7774bff83d09064317d082f",
      "5bb6423c953d417b81547eadd8f60841",
      "1aea5358357448f6bf79b36196c09efb",
      "c70d571d210e4f77a02de7968acdb5c3",
      "7258522cdaaf4617aba68b5f59ec3ab9",
      "ddf1025ca0d64c54b137e95ea5af60b5",
      "3b219e163e0b4c6c93b7a61dc72cc6c3",
      "85bcf96cdd114ff19e92a32beb3ef46b",
      "39e32e5387724c3b91aeb7d529b50432",
      "e2433f289ef54f829e54f6a86bf2ede1",
      "c5d68f7b32664221ae46762192220bfc",
      "671316573c484317a27376ba853d71d5",
      "cbb58f8490da42a6aa51b911939f4bf4",
      "8501ffc4c3f9439facdf42b3e45ce6f8",
      "87f4acc0047e48248897031cbc0ac315",
      "e2fe145a21b648e2b58b5bd0906c3c6a",
      "db81f4b8e9cd4ff2bfcdb26591ff6e8d",
      "17c30b93386f4829bb686c958ba5522f",
      "1264ab588d374831a5cb1cb4049c624e",
      "8abeabca871949498c845f7803ad79eb",
      "aef57a05bc93438eb9952ad3f35304a6",
      "6527fbc9414b4e15afdeef1add313615",
      "d3fe2980bab44d7bb7215dc35d931c4b",
      "9bab39843a764a18bcd4c4eca6bdd08f",
      "f73f5f18cd3b4f2bbefeb1d16733a36c",
      "91547f121ac84a6dae4af04b890728c9",
      "bb4484fbf7824c2aae55198d253593a4",
      "dc67aeacb31a4037857943a574cf8d61",
      "432f7b378a6b453faf7a6542a6b8cd5d",
      "d4955e5016ed4baab54a6014cfcc89f6",
      "56d07849d9dd42faaf13a6d0e19bd42a",
      "75e42a31084e42b69ec61468271153db",
      "3d92549faef744afa5028a3c0863b872",
      "ea8d86b0f73740f293362d61db61143b",
      "83e075f0c7fb4986bb73650349f4cf84",
      "2c4c647c436749c4ab41b3af9e7a62fd",
      "ab06ba38bf4941569a42833c2752f2ac",
      "cc522d8445a84501822a28f4e8786964",
      "59c432d84c9b4e5597d851fcff0192a1",
      "33e92f9562284bcfae45a79877784d25",
      "7657abc7abed419cb4026fc32d4798ad",
      "b47e129ea5014c9c97558ea330c182b6",
      "c796144aa1bc4e5b88b2205fc0b48430",
      "96ec423da9d74dc9b86b70365d3e9eae",
      "8889937d07034457b0b5e1719abfbffd",
      "98048b62e28841ff92a79df02402f020",
      "1f70ee63ff9f477b8d564ddfe71024af",
      "4066062c83434884ad58b2546272829f",
      "4581518736e140ba93729a73a4032ed5",
      "06ca93af19f943d3a93c43396fc2f9df",
      "049e17c2d6a04fa0969c0ad58efa48b9",
      "c2c18a5e2c8844948d68b4c91de72922",
      "c574bdcf4c6c48769345ad608c509408",
      "9710af2b158047309b8897502fce1a76",
      "94368734beaf48b6b47381e36b41fdeb",
      "280f8cb279c540cebb54449a27be5dfa",
      "0108117b215d4d2e84e8b4a70914975b",
      "86c3d0ec74a64c779ba1c5247a97cd39",
      "e0b2094536264e2c8ec1173554202f52",
      "b3feadc7bca540299a9b7281708be1e4",
      "8ae09774329645938779cc7e7ef85019",
      "17dcd7451e02437a96f909e3cbef1b4c",
      "3e1c9cc2f71d4456a4db3341db707c33",
      "8722caae45a1463d8c6d4ec86f82b55a",
      "ac468824a1ed4c40ad338622815dc643",
      "8ca5c3369dbd4ef7a5ff3b42109e3858",
      "2a04be7c3fdb4683b2ccb9be7cc68d5e",
      "7e6256328d8a41bbb7181ed78d917213",
      "e658c25d36414e528405e3bb9e622159",
      "bc2304cddf0f4cc5932d7893c5aa461e",
      "45756bb737d64531b3ad00e8cee9221b",
      "9e96ff5d38284e8996019604552cecda",
      "9f8d7b9a1a75409081be5c4503db11b3",
      "18cbbe82c03045a9b9a7ab44bd065d59",
      "802f8aff829b4c1e82433e7efdf488e9",
      "b0ace3caf7bb48fe884dd7b807a79e84",
      "31ce3e92c18741a0be5c1af884bd10de",
      "d1a1af90501b42e5af58caeb12c8c72e",
      "6ac859a35ac6480bbd5441a852ffd5ff",
      "ab66e35b9582454e89dab62f8b7c769e",
      "25723c74253d450b8fbd3dd163749630",
      "881ac8c21fc948e78eadcf2f9d25eb44",
      "20617002f83e4bf7a8903c8a74bbb71a",
      "b3e0ee6b96044bafb7af2ca455c0b356",
      "af0582a6c7744da5bdbd69bbec092d20",
      "67423b8c3fb24834847c45c315974e03",
      "bca1cf656def4d2c8fe7269e08a34704",
      "cc8a0d4a16714287afd2a9bf99fc5e7e",
      "04c0115f34814061a3f1bb3933aeaee8",
      "3d842c410b2e4298be96b987e7b9a332",
      "e5650b8a5795473aba9ebf66d1ed9aae",
      "901ff693c41445dc9533e00edfb5390c",
      "2cd3bdfea5184a0985e5e94d5c29e81e",
      "6e867cfacd1845a4a45f03b42a77a8af",
      "77418fa41b1a4cad9a69fc6c31272223",
      "d8b71e72821e453cb4d8646791f84dd8",
      "55d08f93dcae418291f0cde9c897ecf8",
      "85fc78a080f148c6bf9fbb9f9e636119",
      "4a3d3fb262784c989a19ee00239f3fa1",
      "d4078e7c064d4d37b8031dea3bb3bdd9",
      "279abb4fa6cf4abeb512be7adf1d4df2",
      "0ac2ea78ef0142d0acf9984064cd077d",
      "bd068a051e404c2a84fd4fe4a0e9e14a",
      "ccc3a484c1894fd0b82b103f8f345018"
     ],
     "base_uri": "https://localhost:8080/",
     "height": 925
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1769762784663,
     "user_tz": -60,
     "elapsed": 281589,
     "user": {
      "displayName": "Dar\u00edo Santos",
      "userId": "05949316178413510452"
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading model: Qwen/Qwen3-8B...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:86: UserWarning: \n",
      "Access to the secret `HF_TOKEN` has not been granted on this notebook.\n",
      "You will not be requested again.\n",
      "Please restart the session if you want to be prompted again.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b4235aa68874675b3e41e2ceef44a72"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8420c0b7dc5e4330ab16be843ad7414c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ec971191511496484d30bd9b65b0771"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e2bf69f1334a46a0a4388a1baf79f41b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/728 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3a9d51f4e194594aaa36ef35044119c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ddf1025ca0d64c54b137e95ea5af60b5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "db81f4b8e9cd4ff2bfcdb26591ff6e8d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00002-of-00005.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dc67aeacb31a4037857943a574cf8d61"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00005-of-00005.safetensors:   0%|          | 0.00/1.24G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "59c432d84c9b4e5597d851fcff0192a1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00004-of-00005.safetensors:   0%|          | 0.00/3.19G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "06ca93af19f943d3a93c43396fc2f9df"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00001-of-00005.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8ae09774329645938779cc7e7ef85019"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00003-of-00005.safetensors:   0%|          | 0.00/3.96G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e96ff5d38284e8996019604552cecda"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "20617002f83e4bf7a8903c8a74bbb71a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e867cfacd1845a4a45f03b42a77a8af"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model Qwen/Qwen3-8B loaded successfully.\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Gold Standard and Sample Data Definition\n",
    "\n",
    "To ensure high-fidelity extraction, we define a \"Gold Standard\" set of entities derived from a representative subset of claims. These examples serve a dual purpose:\n",
    "\n",
    "1. **Few-Shot Prompting:** Providing the model with concrete examples of the desired schema and extraction logic (e.g., distinguishing between a *Material* and a *Doping* condition).\n",
    "2. **Validation:** Establishing a baseline to qualitatively assess the model's performance before processing the full corpus.\n",
    "\n",
    "The extraction schema focuses on the following entity labels:\n",
    "\n",
    "* **Material:** The chemical formula or name of the superconductor.\n",
    "* **State:** The physical state (e.g., *superconductivity*, *ferromagnetism*).\n",
    "* **Property:** Physical properties being measured (e.g., *Tc*, *lattice parameter*).\n",
    "* **Condition:** Experimental conditions (e.g., *doping concentration*, *pressure*).\n",
    "* **Method:** The experimental technique used (e.g., *XRD*, *Resistivity*).\n",
    "* **Measurement Value:** Numerical values associated with properties or conditions.\n"
   ],
   "metadata": {
    "id": "KGNeC3VFEhjH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# --- Gold Standard Data (Ground Truth) ---\n",
    "# These examples represent the strict extraction rules required for the Knowledge Graph.\n",
    "gold_st_entities = [\n",
    "  {\n",
    "    \"claim_id\": \"claim_1\",\n",
    "    \"entities\": [\n",
    "      {\"text\": \"CeO1-xFxBiS2\", \"label\": \"Material\"},\n",
    "      {\"text\": \"ferromagnetism\", \"label\": \"State\"},\n",
    "      {\"text\": \"bulk superconductivity\", \"label\": \"State\"},\n",
    "      {'text': 'high F concentration', 'label': 'Condition'},\n",
    "      {\"text\": \"x > 0.7\", \"label\": \"Measurement Value\"}\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"claim_id\": \"claim_2\",\n",
    "    \"entities\": [\n",
    "      {\"text\": \"NdO1-xFxBiS2\", \"label\": \"Material\"},\n",
    "      {\"text\": \"superconductivity\", \"label\": \"State\"},\n",
    "      {\"text\": \"x=0.1-0.9\", \"label\": \"Measurement Value\"},\n",
    "      {\"text\": \"DC magnetic susceptibility\", \"label\": \"Method\"},\n",
    "      {\"text\": \"electrical transport measurements\", \"label\": \"Method\"}\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"claim_id\": \"claim_3\",\n",
    "    \"entities\": [\n",
    "      {\"text\": \"NdOBiS2\", \"label\": \"Material\"},\n",
    "      {\"text\": \"interband transitions\", \"label\": \"Property\"},\n",
    "      {\"text\": \"first-principles calculations\", \"label\": \"Method\"}\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"claim_id\": \"claim_4\",\n",
    "    \"entities\": [\n",
    "      {\"text\": \"NdO0.7F0.3BiS2\", \"label\": \"Material\"},\n",
    "      {\"text\": \"Tc\", \"label\": \"Property\"},\n",
    "      {\"text\": \"6%\", \"label\": \"Measurement Value\"},\n",
    "      {\"text\": \"Pb concentration\", \"label\": \"Condition\"}\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"claim_id\": \"claim_5\",\n",
    "    \"entities\": [\n",
    "      {\"text\": \"Ce1-xNdxO0.5F0.5BiS2\", \"label\": \"Material\"},\n",
    "      {\"text\": \"length of the a axis\", \"label\": \"Property\"},\n",
    "      {\"text\": \"Nd concentration\", \"label\": \"Condition\"}\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"claim_id\": \"claim_6\",\n",
    "    \"entities\": [\n",
    "      {\"text\": \"electrical resistivity measurements\", \"label\": \"Method\"},\n",
    "      {\"text\": \"applied magnetic field\", \"label\": \"Condition\"},\n",
    "      {\"text\": \"Tc onset\", \"label\": \"Property\"},\n",
    "      {\"text\": \"Tc (\u03c1 =0)\", \"label\": \"Property\"}\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "\n",
    "# --- Sample Input Batch ---\n",
    "# Corresponding text claims used to test the extraction logic.\n",
    "claims = [\n",
    "  {\n",
    "    \"id\": \"claim_1\",\n",
    "    \"text\": \"The crystal structure of CeO1-xFxBiS2 is possibly optimized for the appearance of both ferromagnetism and bulk superconductivity due to high F concentration (x > 0.7)\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"claim_2\",\n",
    "    \"text\": \"All NdO1-xFxBiS2 samples (x=0.1-0.9) exhibit superconductivity confirmed by DC magnetic susceptibility and electrical transport measurements\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"claim_3\",\n",
    "    \"text\": \"The energy scales of the interband transitions in F-substituted NdOBiS2 superconducting single crystals are well reproduced by first-principles calculations\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"claim_4\",\n",
    "    \"text\": \"The Tc of NdO0.7F0.3BiS2 increases with increasing Pb concentration up to 6%\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"claim_5\",\n",
    "    \"text\": \"With increasing Nd concentration, the length of the a axis in Ce1-xNdxO0.5F0.5BiS2 decreased\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"claim_6\",\n",
    "    \"text\": \"Electrical resistivity measurements indicate that under applied magnetic field both Tc onset and Tc (\u03c1 =0) decrease\"\n",
    "  }\n",
    "]"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-26T15:56:05.501356Z",
     "iopub.execute_input": "2026-01-26T15:56:05.501978Z",
     "iopub.status.idle": "2026-01-26T15:56:05.513159Z",
     "shell.execute_reply.started": "2026-01-26T15:56:05.501945Z",
     "shell.execute_reply": "2026-01-26T15:56:05.512546Z"
    },
    "id": "ZfpZZAsd6X9d"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Prompt Engineering and Extraction Logic\n",
    "\n",
    "We define a rigorous system prompt designed to constrain the model's output to a specific JSON schema. The prompt includes:\n",
    "\n",
    "1. **Role Definition:** framing the model as a Materials Scientist.\n",
    "2. **Entity Definitions:** Precise scope for labels like *Material* vs. *Condition*.\n",
    "3. **Few-Shot Examples:** \"Gold Standard\" input-output pairs to guide the reasoning.\n",
    "4. **Negative Constraints:** Explicit rules on what *not* to label (e.g., verbs, pure numbers as conditions).\n"
   ],
   "metadata": {
    "id": "RDbVU8KAGUcu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from threading import Thread\n",
    "from transformers import TextIteratorStreamer\n",
    "\n",
    "# --- 1. System Prompt Definition ---\n",
    "# The /no_think tags are specific instructions to suppress chain-of-thought\n",
    "# verbosity, ensuring the model focuses on generating the JSON payload.\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"/no_think\n",
    "#**System Role:**\n",
    "You are a specialist in Materials Science and Condensed Matter Physics. Your task is to extract structured entities from scientific claims regarding BiS2-based layered superconductors.\n",
    "\n",
    "#**Task:**\n",
    "Analyze the provided text and extract entities based on these definitions:\n",
    "* **Material:** Chemical formulas (e.g., Eu3F4Bi2S4). Only Formulas belong here; exclude modifiers.\n",
    "* **Property:** Quantitative or qualitative attributes measured (e.g., Tc, resistivity, lattice constants).\n",
    "* **State:** Macroscopic phases or high-level physical concepts (e.g., \"Superconductivity\", \"Meissner Effect\", \"CDW\").\n",
    "* **Condition:** External parameters applied (e.g., pressure, temperature, doping concentration).\n",
    "* **Method:** Experimental techniques (e.g., XRD, DFT) or synthesis methods (e.g., Flux method).\n",
    "* **Measurement Value:** The data itself. Scalars, ranges, or inequalities (e.g., \"x > 0.7\", \"2.3 K\", \"high\").\n",
    "\n",
    "#**Output Format:**\n",
    "Return ONLY a valid JSON object with:\n",
    "1. \"claim_id\": The ID provided in the input.\n",
    "2. \"entities\": A list of objects with \"text\" and \"label\".\n",
    "\n",
    "#**Few-Shot Examples:**\n",
    "\n",
    "## Input:\n",
    "{\"claim_id\": \"few_shot_1\", \"text\": \"It was found that the partial substitution of S by Se in LaOBiS2-xSex resulted in the uniaxial lattice expansion along the a axis.\"}\n",
    "\n",
    "## Output:\n",
    "{\n",
    "  \"claim_id\": \"few_shot_1\",\n",
    "  \"entities\": [\n",
    "    {\"text\": \"substitution\", \"label\": \"Condition\"},\n",
    "    {\"text\": \"LaOBiS2-xSex\", \"label\": \"Material\"},\n",
    "    {\"text\": \"uniaxial lattice expansion\", \"label\": \"State\"},\n",
    "    {\"text\": \"a axis\", \"label\": \"Property\"}\n",
    "  ]\n",
    "}\n",
    "\n",
    "## Input:\n",
    "{\"claim_id\": \"few_shot_2\", \"text\": \"The highest Tc (= 2.3 K) was observed for La2O2Bi3Ag0.6Sn0.4S6.\"}\n",
    "\n",
    "## Output:\n",
    "{\n",
    "  \"claim_id\": \"few_shot_2\",\n",
    "  \"entities\": [\n",
    "    {\"text\": \"Tc\", \"label\": \"Property\"},\n",
    "    {\"text\": \"2.3 K\", \"label\": \"Measurement Value\"},\n",
    "    {\"text\": \"La2O2Bi3Ag0.6Sn0.4S6\", \"label\": \"Material\"}\n",
    "  ]\n",
    "}\n",
    "\n",
    "#**Extraction Rules:**\n",
    "1. **CRITICAL:** If you are unsure, DO NOT LABEL.\n",
    "2. **Values:** Capture the whole string (scalar + unit, or inequality).\n",
    "3. **Materials:** Strip modifiers. \"F-Substituted Eu3F4Bi2S4\" -> \"Eu3F4Bi2S4\".\n",
    "4. **Numbers:** Pure numbers are \"Measurement Values\", NEVER \"Conditions\".\n",
    "5. **Verbs:** Do not capture verbs.\n",
    "\"\"\"\n",
    "\n",
    "def clean_and_parse_json(response_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Robustly extracts and parses JSON from the LLM response, handling\n",
    "    potential thinking traces or preamble text.\n",
    "    \"\"\"\n",
    "    # 1. Remove potential closing tags if reasoning models are used\n",
    "    if \"</think>\" in response_text:\n",
    "        response_text = response_text.split(\"</think>\")[-1]\n",
    "\n",
    "    # 2. Use Regex to find the outermost JSON object\n",
    "    # This matches everything between the first '{' and the last '}'\n",
    "    match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "\n",
    "    if match:\n",
    "        json_str = match.group(0)\n",
    "        try:\n",
    "            return json.loads(json_str)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"\u26a0\ufe0f JSON Decode Error. Raw string: {json_str[:50]}...\")\n",
    "            return {\"entities\": []}\n",
    "    else:\n",
    "        print(\"\u26a0\ufe0f No JSON object found in response.\")\n",
    "        return {\"entities\": []}\n",
    "\n",
    "def extract_entities(model, tokenizer, input_claim: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Runs the inference loop for a single claim.\n",
    "\n",
    "    Args:\n",
    "        model: Loaded HF model.\n",
    "        tokenizer: Loaded HF tokenizer.\n",
    "        input_claim (dict): A dictionary containing 'id' and 'text'.\n",
    "\n",
    "    Returns:\n",
    "        dict: The extracted entities in JSON format.\n",
    "    \"\"\"\n",
    "    # Construct the message\n",
    "    # We serialize the specific input claim to JSON to pass it into the prompt context\n",
    "    input_str = json.dumps({\"claim_id\": input_claim[\"id\"], \"text\": input_claim[\"text\"]})\n",
    "\n",
    "    # Combine System Prompt + Input\n",
    "    # Note: We append /no_think at the end to reinforce the instruction\n",
    "    full_user_content = f\"{SYSTEM_PROMPT}\\n\\n##**Input:**\\n{input_str}\\n\\n/no_think\"\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": full_user_content}]\n",
    "\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # Initialize Streamer\n",
    "    streamer = TextIteratorStreamer(\n",
    "        tokenizer, skip_prompt=True, skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "    generation_kwargs = dict(\n",
    "        model_inputs,\n",
    "        streamer=streamer,\n",
    "        max_new_tokens=1024,\n",
    "        do_sample=False, # Greedy decoding for reproducibility\n",
    "        temperature=0.1  # Low temp for factual extraction (ignored if do_sample=False, but good practice)\n",
    "    )\n",
    "\n",
    "    # Run Generation in a separate thread\n",
    "    thread = Thread(target=model.generate, kwargs=generation_kwargs)\n",
    "    thread.start()\n",
    "\n",
    "    # Consume Stream\n",
    "    print(f\"Processing Claim: {input_claim['id']}\")\n",
    "    response_chunks = []\n",
    "    for new_text in streamer:\n",
    "        # Optional: Print to console if you want real-time debugging\n",
    "        # print(new_text, end=\"\", flush=True)\n",
    "        response_chunks.append(new_text)\n",
    "\n",
    "    full_response = \"\".join(response_chunks)\n",
    "\n",
    "    # Parse and Return\n",
    "    return clean_and_parse_json(full_response)\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-26T15:17:12.115982Z",
     "iopub.execute_input": "2026-01-26T15:17:12.116276Z",
     "iopub.status.idle": "2026-01-26T15:17:12.126581Z",
     "shell.execute_reply.started": "2026-01-26T15:17:12.116236Z",
     "shell.execute_reply": "2026-01-26T15:17:12.126003Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "id": "7fWBLdNm6X9d"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### 4.1 Extraction Logic Implementation\n",
    "\n",
    "This section defines the core inference function `extract_entities_2`. It encapsulates the prompt, model generation, and a robust JSON recovery mechanism to handle potential formatting errors from the LLM.\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "* **Streaming Support:** Real-time console output for monitoring generation speed and quality.\n",
    "* **Thinking Control:** Toggles the model's \"Chain of Thought\" (via `/no_think`) to balance reasoning depth against token usage.\n",
    "* **Robust JSON Parsing:** A `recover_json` helper function repairs common syntax errors (e.g., trailing commas, missing brackets) before parsing.\n"
   ],
   "metadata": {
    "id": "po3oypcRHLji"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "def extract_entities_2(model, tokenizer, input_data, streaming=True, thinking=False):\n",
    "    \"\"\"\n",
    "    Extracts entities from a single claim using Qwen with optional streaming and thinking modes.\n",
    "    Includes robust JSON recovery for malformed model outputs.\n",
    "    \"\"\"\n",
    "\n",
    "    # Toggle for Qwen's reasoning mode\n",
    "    think_tag = \"\" if thinking else \"/no_think\"\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    #**System Role:**\n",
    "    You are a specialist in Materials Science and Condensed Matter Physics World. You thrive at interpreting the entities displayed in scientific texts claims and label the according to their nature. Your task is to extract structured entities from scientific text regarding BiS2-based layered superconductors.\n",
    "\n",
    "    #**Task:**\n",
    "    Analyze the provided text and extract entities based on the definitions:\n",
    "    * **Material:** Chemical formulas that represent and samples compounds (e.g., Eu3F4Bi2S4). Only Formulas belong here, no modifiers or eleent sustitutors.\n",
    "    * **Property:** These entities represent the quantitative or qualitative attributes of a material. They are the specific variables that researchers measure to characterize a material, such as how it conducts electricity, responds to magnetic fields, or its geometric dimensions.(e.g., Tc, resistivity, lattice constants).\n",
    "    * **State:** These entities describe the macroscopic states or effects a material exhibits. Unlike simple properties, these are high-level physical concepts or phases of matter (e.g., \"Superconductivity\",Meissner Effect, Charge Density Wave (CDW), Specific Heat Anomaly , Flux Pinning , Isotope Effect.) that the material enters under specific conditions.\n",
    "    * **Condition:** External parameters (e.g., pressure, temperature, doping concentration-> elements substitution belongs here,e.g. F-substituted + material, High Magnetic Field,...) applied during the experiment.\n",
    "    * **Method:** Techniques used to measure properties (e.g., XRD, DFT, solid-state reaction) OR techniques used to create the material (e.g., Solid-state reaction, High-pressure synthesis, Vacuum encapsulation, Flux method (CsCl/KCl), Arc melting, Thin film deposition (PLD, MBE))\n",
    "    * **Measurement Value:** Nodes representing the extracted data itself. These are structured objects that standardize raw text into queryable formats, capturing Scalars, Ranges, Constraints, and Qualitative descriptors along with their units and quantifiers.\n",
    "\n",
    "    #**Output Format:**\n",
    "    Return only a valid JSON object with the \"claim_id\" key followed by the value str AND \"entities\", containing a list of objects with \"text\" and \"label\"\n",
    "\n",
    "    #**Few-Shot Examples:**\n",
    "\n",
    "    ##**Input:**\n",
    "    {\"claim_id\": \"few_shot_1\", \"text\": \"It was found that the partial substitution of S by Se in LaOBiS2-xSex resulted in the uniaxial lattice expansion along the a axis.\"}\n",
    "\n",
    "    ##**Output:**\n",
    "    {\n",
    "      \"claim_id\": \"few_shot_1\",\n",
    "      \"entities\": [\n",
    "        {\"text\": \"substitution\", \"label\": \"Condition\"},\n",
    "        {\"text\": \"LaOBiS2-xSex\", \"label\": \"Material\"},\n",
    "        {\"text\": \"uniaxial lattice expansion\", \"label\": \"State\"},\n",
    "        {\"text\": \"a axis\", \"label\": \"Property\"}\n",
    "      ]\n",
    "    }\n",
    "\n",
    "    ##**Input:**\n",
    "    {\"claim_id\": \"few_shot_2\", \"text\": \"The highest Tc (= 2.3 K) was observed for La2O2Bi3Ag0.6Sn0.4S6.\"}\n",
    "\n",
    "    ##**Output:**\n",
    "    {\n",
    "      \"claim_id\": \"few_shot_2\",\n",
    "      \"entities\": [\n",
    "        {\"text\": \"Tc\", \"label\": \"Property\"},\n",
    "        {\"text\": \"2.3 K\", \"label\": \"Measurement Value\"},\n",
    "        {\"text\": \"La2O2Bi3Ag0.6Sn0.4S6\", \"label\": \"Material\"}\n",
    "      ]\n",
    "    }\n",
    "\n",
    "    #**Extraction Rules:**\n",
    "    1.CRITICAL-> DO NOT FORCE LABELING: If you are not sure about a specific entity DO NOT LABEL.\n",
    "    2.Measurement values can consist in scalars constraints or inequalities (y < 6), ranges , percentages (0.9%) or quantitative words e.g. \"high\", \"low\" AND/ OR SCALAR + units. Capture the whole string representing the value if one of them appear.\n",
    "    3.\"Examples are guides\": You will come across entities that are not stated in examples. Use to intuition to correctly label them.\n",
    "    4.CRITICAL -> Materials extraction: In order to prevent noise, if a specific material is presented with modifiers  **get ONLY the material formula** (E.g \"F-Substituted Eu3F4Bi2S4\" = \"Eu3F4Bi2S4\").\n",
    "    5.Numbers (besides formulas') can ONLY fit in \"Measurement Values\" they will NEVER be a CONDITION.\n",
    "    6.Do not capture VERBS as any of these labels. They do not belong in this classification.\n",
    "    \"\"\"\n",
    "\n",
    "    inpt = f\"\\n #**INPUT\\n {input_data}\"\n",
    "    full_prompt = think_tag + prompt + str(inpt) + think_tag\n",
    "    messages = [{\"role\": \"user\", \"content\": full_prompt}]\n",
    "\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    generation_kwargs = dict(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=1024,\n",
    "        temperature=0.1,\n",
    "        do_sample=False\n",
    "    )\n",
    "\n",
    "    # \ud83e\udde0 STREAMING MODE\n",
    "    if streaming:\n",
    "        streamer = TextIteratorStreamer(\n",
    "            tokenizer,\n",
    "            skip_prompt=True,\n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "\n",
    "        generation_kwargs[\"streamer\"] = streamer\n",
    "\n",
    "        # Run in background thread\n",
    "        thread = Thread(target=model.generate, kwargs=generation_kwargs)\n",
    "        thread.start()\n",
    "\n",
    "        # Live Stream to Console\n",
    "        print(\"--- Model Thinking/Output Starting ---\\n\")\n",
    "        response_chunks = []\n",
    "        print(f\"Raw claim: {input_data}\")\n",
    "\n",
    "        for new_text in streamer:\n",
    "            print(new_text, end=\"\", flush=True)\n",
    "            response_chunks.append(new_text)\n",
    "\n",
    "        print(\"\\n--- Generation Complete ---\\n\")\n",
    "        full_response = \"\".join(response_chunks)\n",
    "\n",
    "    # \ud83e\udde0 NON-STREAM MODE\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(**generation_kwargs)\n",
    "        full_response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # \ud83d\udd27 Remove thinking blocks if present\n",
    "    if \"</think>\" in full_response:\n",
    "        full_response = full_response.split(\"</think>\")[-1]\n",
    "\n",
    "    # \ud83d\udee0 Robust JSON recovery\n",
    "    def recover_json(text):\n",
    "        start = text.find(\"{\")\n",
    "        end = text.rfind(\"}\")\n",
    "        if start == -1 or end == -1:\n",
    "            return None\n",
    "        text = text[start:end+1]\n",
    "        # Remove trailing commas before closing braces/brackets\n",
    "        text = re.sub(r\",\\s*([}\\]])\", r\"\\1\", text)\n",
    "\n",
    "        # Balance braces if truncated\n",
    "        open_braces = text.count(\"{\") - text.count(\"}\")\n",
    "        open_brackets = text.count(\"[\") - text.count(\"]\")\n",
    "        text += \"}\" * max(0, open_braces)\n",
    "        text += \"]\" * max(0, open_brackets)\n",
    "        return text\n",
    "\n",
    "    try:\n",
    "        cleaned = recover_json(full_response)\n",
    "        return json.loads(cleaned) if cleaned else {\"entities\": []}\n",
    "    except Exception as e:\n",
    "        print(f\"\u26a0\ufe0f JSON parse failed: {e}\")\n",
    "        return {\"entities\": []}\n"
   ],
   "metadata": {
    "id": "IDc1vWBHHHAz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "## \ud83d\udd0e Entity Extraction Pipeline \u2014 Streaming LLM Inference\n",
    "\n",
    "This function implements an **LLM-driven scientific entity extraction pipeline** tailored for **BiS\u2082-based superconductor literature**. Each claim is processed independently and converted into structured knowledge-graph entities.\n",
    "\n",
    "### \u2699\ufe0f General Logic\n",
    "\n",
    "1. **Prompt Construction**\n",
    "   A domain-specialized instruction prompt defines:\n",
    "\n",
    "   * The **entity ontology** (Material, Property, State, Condition, Method, Measurement Value)\n",
    "   * Strict extraction rules to reduce noise (e.g., formulas only for Materials, no verbs, no forced labeling).\n",
    "\n",
    "2. **Chat Formatting**\n",
    "   The claim is wrapped using the tokenizer\u2019s chat template to match the model\u2019s instruction-tuned format.\n",
    "\n",
    "3. **LLM Generation**\n",
    "   The model produces a **JSON-only structured response** containing:\n",
    "\n",
    "   * `claim_id`\n",
    "   * a list of extracted `entities`\n",
    "\n",
    "4. **Streaming Output (Optional)**\n",
    "   When enabled, generation is streamed token-by-token using a `TextIteratorStreamer`, allowing:\n",
    "\n",
    "   * Real-time monitoring\n",
    "   * Early detection of malformed outputs\n",
    "   * Better debugging of model behavior\n",
    "\n",
    "5. **Thinking Mode Control**\n",
    "   The `thinking` flag allows inclusion/removal of reasoning traces (`<think>` blocks), improving:\n",
    "\n",
    "   * Speed (off)\n",
    "   * Interpretability (on)\n",
    "\n",
    "6. **Post-Processing**\n",
    "   The raw text output is cleaned, the JSON block is isolated, and safely parsed. Failures return an empty structured object instead of breaking the pipeline.\n",
    "\n",
    "7. **Batch Processing with Progress Bar**\n",
    "   Claims are processed inside a `tqdm` loop, providing:\n",
    "\n",
    "   * Visual progress tracking\n",
    "   * Stable iteration over large datasets\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83d\ude80 Improvements Over Basic Inference\n",
    "\n",
    "| Feature                                     | Benefit                                |\n",
    "| ------------------------------------------- | -------------------------------------- |\n",
    "| **Streaming generation**                    | Live visibility into model output      |\n",
    "| **Strict ontology enforcement**             | Cleaner, KG-ready data                 |\n",
    "| **Deterministic decoding**                  | Reproducible extraction                |\n",
    "| **Robust JSON cleaning**                    | Prevents crashes from malformed output |\n",
    "| **Modular flags (`streaming`, `thinking`)** | Flexible debugging vs production modes |\n",
    "| **Per-claim processing**                    | Fault isolation and easier evaluation  |\n",
    "\n",
    "---\n",
    "\n",
    "This design turns a general LLM into a **controlled information extraction engine** suitable for building a structured superconductivity knowledge graph.\n"
   ],
   "metadata": {
    "id": "rXiZU5Fp6X9e"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### 5.1 Batch Execution and Verification\n",
    "\n",
    "We now execute the entity extraction pipeline over the dataset.\n",
    "\n",
    "* **Progress Tracking:** We use `tqdm` to monitor the inference progress.\n",
    "* **Visual Validation:** A structured table is printed for each claim, allowing for real-time verification of the entity-label alignment."
   ],
   "metadata": {
    "id": "U9mgJZp9HiLo"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Container for storing results\n",
    "pred_entities = []\n",
    "\n",
    "# Iterate over the sample claims\n",
    "for claim in tqdm(claims, desc=\"Extracting Entities\", colour=\"green\"):\n",
    "    # Execute Inference\n",
    "    result = extract_entities_2(\n",
    "        model,\n",
    "        tokenizer,\n",
    "        claim,\n",
    "        streaming=True, # Disable streaming for clean batch output\n",
    "        thinking=False   # Disable 'thinking' to save tokens/time\n",
    "    )\n",
    "\n",
    "    # --- Structured Console Visualization ---\n",
    "    claim_id = result.get(\"claim_id\", \"Unknown\")\n",
    "    entities = result.get(\"entities\", [])\n",
    "    claim_text = claim.get('text', 'No text provided')\n",
    "\n",
    "    print(f\"\\n\u250f\u2501 Claim ID: {claim_id}\")\n",
    "    print(f\"\u2503  Raw Input: {claim_text[:80]}...\" if len(claim_text) > 80 else f\"\u2503  Raw Input: {claim_text}\")\n",
    "    print(f\"\u2523{'\u2501'*31}\u2533{'\u2501'*20}\u2513\")\n",
    "    print(f\"\u2503 {'ENTITY TEXT':<30} \u2503 {'LABEL':<18} \u2503\")\n",
    "    print(f\"\u2523{'\u2501'*31}\u254b{'\u2501'*20}\u252b\")\n",
    "\n",
    "    if not entities:\n",
    "        print(f\"\u2503 {'(No entities found)':<30} \u2503 {'-':<18} \u2503\")\n",
    "    else:\n",
    "        for ent in entities:\n",
    "            text = str(ent.get(\"text\", \"\"))\n",
    "            label = str(ent.get(\"label\", \"\"))\n",
    "\n",
    "            # Truncate text if it's too long for the column visualization\n",
    "            text_disp = (text[:27] + '..') if len(text) > 29 else text\n",
    "\n",
    "            print(f\"\u2503 {text_disp:<30} \u2503 {label:<18} \u2503\")\n",
    "\n",
    "    print(f\"\u2517{'\u2501'*31}\u253b{'\u2501'*20}\u251b\")\n",
    "    print(\"\u2705 Result added to predictions\\n\")\n",
    "    # ------------------------------------\n",
    "\n",
    "    pred_entities.append(result)\n",
    "\n",
    "# Final Summary\n",
    "print(f\"Successfully processed {len(pred_entities)} claims.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "7202144c55ad4f0aa835fad1385935cd",
      "3881e81890e34e9fb93acdf2a41305d4",
      "dfd26897caf34223b2c0c50c14a461dc",
      "4b7873704f6b4cfcba0290822929ad61",
      "1ce5fe4d4fd3429ca2207a9942948ba3",
      "d481a35d13bb41ada68e9abaefb104b0",
      "bd00840a0999442f8f79ee0db886c876",
      "c9d57a950eb24a6daa355376e0afb3fe",
      "e11553fb5fbe410dba75edff53b3f51e",
      "882bc36dbb70456b86b5d23c8490a047",
      "8349fc61ea8c4364ac460c19867bc452"
     ]
    },
    "id": "p7LigmwIH-JQ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1769764093886,
     "user_tz": -60,
     "elapsed": 570107,
     "user": {
      "displayName": "Dar\u00edo Santos",
      "userId": "05949316178413510452"
     }
    },
    "outputId": "629a1dd7-50a5-43b7-cbf0-3d6a9e98d4d3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Extracting Entities:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7202144c55ad4f0aa835fad1385935cd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- Model Thinking/Output Starting ---\n",
      "\n",
      "Raw claim: {'id': 'claim_1', 'text': 'The crystal structure of CeO1-xFxBiS2 is possibly optimized for the appearance of both ferromagnetism and bulk superconductivity due to high F concentration (x > 0.7)'}\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "{\n",
      "  \"claim_id\": \"claim_1\",\n",
      "  \"entities\": [\n",
      "    {\"text\": \"CeO1-xFxBiS2\", \"label\": \"Material\"},\n",
      "    {\"text\": \"ferromagnetism\", \"label\": \"State\"},\n",
      "    {\"text\": \"bulk superconductivity\", \"label\": \"State\"},\n",
      "    {\"text\": \"high F concentration\", \"label\": \"Condition\"},\n",
      "    {\"text\": \"x > 0.7\", \"label\": \"Measurement Value\"}\n",
      "  ]\n",
      "}\n",
      "--- Generation Complete ---\n",
      "\n",
      "\n",
      "\u250f\u2501 Claim ID: claim_1\n",
      "\u2503  Raw Input: The crystal structure of CeO1-xFxBiS2 is possibly optimized for the appearance o...\n",
      "\u2523\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n",
      "\u2503 ENTITY TEXT                    \u2503 LABEL              \u2503\n",
      "\u2523\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u254b\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u252b\n",
      "\u2503 CeO1-xFxBiS2                   \u2503 Material           \u2503\n",
      "\u2503 ferromagnetism                 \u2503 State              \u2503\n",
      "\u2503 bulk superconductivity         \u2503 State              \u2503\n",
      "\u2503 high F concentration           \u2503 Condition          \u2503\n",
      "\u2503 x > 0.7                        \u2503 Measurement Value  \u2503\n",
      "\u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u253b\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251b\n",
      "\u2705 Result added to predictions\n",
      "\n",
      "--- Model Thinking/Output Starting ---\n",
      "\n",
      "Raw claim: {'id': 'claim_2', 'text': 'All NdO1-xFxBiS2 samples (x=0.1-0.9) exhibit superconductivity confirmed by DC magnetic susceptibility and electrical transport measurements'}\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "{\n",
      "  \"claim_id\": \"claim_2\",\n",
      "  \"entities\": [\n",
      "    {\"text\": \"NdO1-xFxBiS2\", \"label\": \"Material\"},\n",
      "    {\"text\": \"x=0.1-0.9\", \"label\": \"Condition\"},\n",
      "    {\"text\": \"superconductivity\", \"label\": \"State\"},\n",
      "    {\"text\": \"DC magnetic susceptibility\", \"label\": \"Method\"},\n",
      "    {\"text\": \"electrical transport measurements\", \"label\": \"Method\"}\n",
      "  ]\n",
      "}\n",
      "--- Generation Complete ---\n",
      "\n",
      "\n",
      "\u250f\u2501 Claim ID: claim_2\n",
      "\u2503  Raw Input: All NdO1-xFxBiS2 samples (x=0.1-0.9) exhibit superconductivity confirmed by DC m...\n",
      "\u2523\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n",
      "\u2503 ENTITY TEXT                    \u2503 LABEL              \u2503\n",
      "\u2523\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u254b\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u252b\n",
      "\u2503 NdO1-xFxBiS2                   \u2503 Material           \u2503\n",
      "\u2503 x=0.1-0.9                      \u2503 Condition          \u2503\n",
      "\u2503 superconductivity              \u2503 State              \u2503\n",
      "\u2503 DC magnetic susceptibility     \u2503 Method             \u2503\n",
      "\u2503 electrical transport measur..  \u2503 Method             \u2503\n",
      "\u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u253b\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251b\n",
      "\u2705 Result added to predictions\n",
      "\n",
      "--- Model Thinking/Output Starting ---\n",
      "\n",
      "Raw claim: {'id': 'claim_3', 'text': 'The energy scales of the interband transitions in F-substituted NdOBiS2 superconducting single crystals are well reproduced by first-principles calculations'}\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "{\n",
      "  \"claim_id\": \"claim_3\",\n",
      "  \"entities\": [\n",
      "    {\"text\": \"F-substituted NdOBiS2\", \"label\": \"Material\"},\n",
      "    {\"text\": \"interband transitions\", \"label\": \"Property\"},\n",
      "    {\"text\": \"first-principles calculations\", \"label\": \"Method\"}\n",
      "  ]\n",
      "}\n",
      "--- Generation Complete ---\n",
      "\n",
      "\n",
      "\u250f\u2501 Claim ID: claim_3\n",
      "\u2503  Raw Input: The energy scales of the interband transitions in F-substituted NdOBiS2 supercon...\n",
      "\u2523\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n",
      "\u2503 ENTITY TEXT                    \u2503 LABEL              \u2503\n",
      "\u2523\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u254b\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u252b\n",
      "\u2503 F-substituted NdOBiS2          \u2503 Material           \u2503\n",
      "\u2503 interband transitions          \u2503 Property           \u2503\n",
      "\u2503 first-principles calculations  \u2503 Method             \u2503\n",
      "\u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u253b\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251b\n",
      "\u2705 Result added to predictions\n",
      "\n",
      "--- Model Thinking/Output Starting ---\n",
      "\n",
      "Raw claim: {'id': 'claim_4', 'text': 'The Tc of NdO0.7F0.3BiS2 increases with increasing Pb concentration up to 6%'}\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "{\n",
      "  \"claim_id\": \"claim_4\",\n",
      "  \"entities\": [\n",
      "    {\"text\": \"Tc\", \"label\": \"Property\"},\n",
      "    {\"text\": \"NdO0.7F0.3BiS2\", \"label\": \"Material\"},\n",
      "    {\"text\": \"Pb concentration\", \"label\": \"Condition\"},\n",
      "    {\"text\": \"6%\", \"label\": \"Measurement Value\"}\n",
      "  ]\n",
      "}\n",
      "--- Generation Complete ---\n",
      "\n",
      "\n",
      "\u250f\u2501 Claim ID: claim_4\n",
      "\u2503  Raw Input: The Tc of NdO0.7F0.3BiS2 increases with increasing Pb concentration up to 6%\n",
      "\u2523\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n",
      "\u2503 ENTITY TEXT                    \u2503 LABEL              \u2503\n",
      "\u2523\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u254b\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u252b\n",
      "\u2503 Tc                             \u2503 Property           \u2503\n",
      "\u2503 NdO0.7F0.3BiS2                 \u2503 Material           \u2503\n",
      "\u2503 Pb concentration               \u2503 Condition          \u2503\n",
      "\u2503 6%                             \u2503 Measurement Value  \u2503\n",
      "\u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u253b\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251b\n",
      "\u2705 Result added to predictions\n",
      "\n",
      "--- Model Thinking/Output Starting ---\n",
      "\n",
      "Raw claim: {'id': 'claim_5', 'text': 'With increasing Nd concentration, the length of the a axis in Ce1-xNdxO0.5F0.5BiS2 decreased'}\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "{\n",
      "  \"claim_id\": \"claim_5\",\n",
      "  \"entities\": [\n",
      "    {\"text\": \"Nd concentration\", \"label\": \"Condition\"},\n",
      "    {\"text\": \"a axis\", \"label\": \"Property\"},\n",
      "    {\"text\": \"Ce1-xNdxO0.5F0.5BiS2\", \"label\": \"Material\"}\n",
      "  ]\n",
      "}\n",
      "--- Generation Complete ---\n",
      "\n",
      "\n",
      "\u250f\u2501 Claim ID: claim_5\n",
      "\u2503  Raw Input: With increasing Nd concentration, the length of the a axis in Ce1-xNdxO0.5F0.5Bi...\n",
      "\u2523\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n",
      "\u2503 ENTITY TEXT                    \u2503 LABEL              \u2503\n",
      "\u2523\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u254b\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u252b\n",
      "\u2503 Nd concentration               \u2503 Condition          \u2503\n",
      "\u2503 a axis                         \u2503 Property           \u2503\n",
      "\u2503 Ce1-xNdxO0.5F0.5BiS2           \u2503 Material           \u2503\n",
      "\u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u253b\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251b\n",
      "\u2705 Result added to predictions\n",
      "\n",
      "--- Model Thinking/Output Starting ---\n",
      "\n",
      "Raw claim: {'id': 'claim_6', 'text': 'Electrical resistivity measurements indicate that under applied magnetic field both Tc onset and Tc (\u03c1 =0) decrease'}\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "{\n",
      "  \"claim_id\": \"claim_6\",\n",
      "  \"entities\": [\n",
      "    {\"text\": \"Electrical resistivity\", \"label\": \"Property\"},\n",
      "    {\"text\": \"magnetic field\", \"label\": \"Condition\"},\n",
      "    {\"text\": \"Tc onset\", \"label\": \"State\"},\n",
      "    {\"text\": \"Tc (\u03c1 =0)\", \"label\": \"Property\"},\n",
      "    {\"text\": \"\u03c1 =0\", \"label\": \"Measurement Value\"}\n",
      "  ]\n",
      "}\n",
      "--- Generation Complete ---\n",
      "\n",
      "\n",
      "\u250f\u2501 Claim ID: claim_6\n",
      "\u2503  Raw Input: Electrical resistivity measurements indicate that under applied magnetic field b...\n",
      "\u2523\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n",
      "\u2503 ENTITY TEXT                    \u2503 LABEL              \u2503\n",
      "\u2523\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u254b\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u252b\n",
      "\u2503 Electrical resistivity         \u2503 Property           \u2503\n",
      "\u2503 magnetic field                 \u2503 Condition          \u2503\n",
      "\u2503 Tc onset                       \u2503 State              \u2503\n",
      "\u2503 Tc (\u03c1 =0)                      \u2503 Property           \u2503\n",
      "\u2503 \u03c1 =0                           \u2503 Measurement Value  \u2503\n",
      "\u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u253b\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251b\n",
      "\u2705 Result added to predictions\n",
      "\n",
      "Successfully processed 6 claims.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 6. Model Validation: Quantitative Metrics\n",
    "\n",
    "To assess the performance of Qwen 3 (8B) on the Entity Extraction task, we compare the generated predictions against the manually annotated \"Gold Standard\" defined in Section 3.\n",
    "\n",
    "We utilize standard Information Retrieval metrics to quantify performance:\n",
    "\n",
    "* **Precision:** The proportion of extracted entities that are correct (Formula: ). High precision indicates low \"noise\".\n",
    "* **Recall:** The proportion of actual entities that were successfully retrieved (Formula: ). High recall indicates high \"completeness\".\n",
    "* **F1-Score:** The harmonic mean of Precision and Recall, providing a single balanced metric.\n"
   ],
   "metadata": {
    "id": "04Wxwd3J6X9g"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "def calculate_detailed_metrics(pred_entities, gold_entities):\n",
    "    \"\"\"\n",
    "    Calculates Precision, Recall, and F1 score by comparing predicted entities\n",
    "    against gold standard entities.\n",
    "\n",
    "    Matching is done based on the lowercased text string and the label.\n",
    "    \"\"\"\n",
    "    # Create sets of tuples (text, label) for set operations\n",
    "    pred_set = {(e['text'].lower().strip(), e['label']) for e in pred_entities}\n",
    "    gold_set = {(e['text'].lower().strip(), e['label']) for e in gold_entities}\n",
    "\n",
    "    # Calculate True Positives, False Positives, and False Negatives\n",
    "    tp_set = pred_set.intersection(gold_set)\n",
    "    fp_set = pred_set - gold_set\n",
    "    fn_set = gold_set - pred_set\n",
    "\n",
    "    tp, fp, fn = len(tp_set), len(fp_set), len(fn_set)\n",
    "\n",
    "    # Safe division to handle zero denominators\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision, \"recall\": recall, \"f1\": f1,\n",
    "        \"tp_list\": tp_set, \"fp_list\": fp_set, \"fn_list\": fn_set\n",
    "    }\n",
    "\n",
    "# --- Execution of Validation ---\n",
    "\n",
    "# create a lookup dictionary for the Gold Standard\n",
    "gold_lookup = {item['claim_id']: item['entities'] for item in gold_st_entities}\n",
    "report_data = []\n",
    "\n",
    "print(f\"\\n{'ID':<10} | {'Prec.':<7} | {'Rec.':<7} | {'F1':<7} | {'Status'}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for pred in pred_entities:\n",
    "    cid = pred['claim_id']\n",
    "\n",
    "    if cid in gold_lookup:\n",
    "        m = calculate_detailed_metrics(pred['entities'], gold_lookup[cid])\n",
    "        report_data.append(m)\n",
    "\n",
    "        # Visual indicator logic\n",
    "        status = \"\u2705 Perfect\" if m['f1'] == 1.0 else \"\u26a0\ufe0f Partial\" if m['f1'] > 0 else \"\u274c Fail\"\n",
    "\n",
    "        print(f\"{cid:<10} | {m['precision']:<7.2f} | {m['recall']:<7.2f} | {m['f1']:<7.2f} | {status}\")\n",
    "    else:\n",
    "        print(f\"{cid:<10} | {'Skipped (No Gold Std)':<30}\")\n",
    "\n",
    "# --- Aggregate Metrics (Macro-Average) ---\n",
    "if report_data:\n",
    "    avg_f1 = sum(r['f1'] for r in report_data) / len(report_data)\n",
    "    avg_prec = sum(r['precision'] for r in report_data) / len(report_data)\n",
    "    avg_rec = sum(r['recall'] for r in report_data) / len(report_data)\n",
    "\n",
    "    print(\"-\" * 55)\n",
    "    print(f\"{'OVERALL':<10} | {avg_prec:<7.2f} | {avg_rec:<7.2f} | {avg_f1:<7.2f} | Score: {avg_f1*100:.1f}%\")\n",
    "else:\n",
    "    print(\"\\nNo validation data available.\")\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-26T16:02:54.22812Z",
     "iopub.execute_input": "2026-01-26T16:02:54.228666Z",
     "iopub.status.idle": "2026-01-26T16:02:54.239118Z",
     "shell.execute_reply.started": "2026-01-26T16:02:54.228637Z",
     "shell.execute_reply": "2026-01-26T16:02:54.238473Z"
    },
    "id": "XPokmFDv6X9g",
    "outputId": "87d20343-b698-4811-8583-02846db7ee19"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "ID         | Prec.   | Rec.    | F1      | Status\n-------------------------------------------------------\nclaim_1    | 0.80    | 0.80    | 0.80    | \u26a0\ufe0f Partial\nclaim_2    | 0.80    | 0.80    | 0.80    | \u26a0\ufe0f Partial\nclaim_3    | 0.67    | 0.67    | 0.67    | \u26a0\ufe0f Partial\nclaim_4    | 1.00    | 1.00    | 1.00    | \u2705 Perfect\nclaim_5    | 0.67    | 0.67    | 0.67    | \u26a0\ufe0f Partial\nclaim_6    | 0.80    | 1.00    | 0.89    | \u26a0\ufe0f Partial\n-------------------------------------------------------\nOVERALL    | 0.79    | 0.82    | 0.80    | Score: 80.4%\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "### 6.1 Performance Analysis & Conclusion\n",
    "\n",
    "The entity extraction pipeline is now fully operational and validated against the gold standard. Based on the comparison between the predicted and ground-truth sets, we can draw the following conclusions:\n",
    "\n",
    "#### 1. The Boundary Issue (Claim 5 & 1)\n",
    "\n",
    "The lowest scores, particularly in **Claim 5**, are not necessarily due to \"incorrect\" extractions but rather **entity boundary mismatches**.\n",
    "\n",
    "* **Example:** In Claim 5, the gold standard identifies `\"length of the a axis\"`, while the model extracted `\"a axis\"`.\n",
    "* **Example:** In Claim 1, the model captured `\"high F concentration\"` (Condition), while the gold standard expected `\"high\"` (Measurement Value).\n",
    "These are stylistic differences in how the span of the entity is defined. The model is correctly identifying the *concepts*, but the strict tuple-matching logic penalizes it for not matching the exact character span of the gold standard.\n",
    "\n",
    "#### 2. Label Consistency\n",
    "\n",
    "The model shows high reliability in assigning the correct labels (Material, Property, Method). Errors in \"State\" vs \"Condition\" are minimal, suggesting the schema is well-understood by the model.\n",
    "\n",
    "#### 3. Ready for Batch Processing\n",
    "\n",
    "With the logic for `claim_id` matching now fixed and the evaluation loop successfully handling dictionary outputs, we are **fully set for whole-batch entity extraction**. The system is robust enough to process large datasets while maintaining the link between the original claim and its extracted metadata.\n",
    "\n",
    "**Would you like me to implement a \"fuzzy matching\" logic that gives partial credit for overlapping text boundaries?**"
   ],
   "metadata": {
    "id": "cB1K4vTN6X9g"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Full Corpus Processing (Resumable Strategy)\n",
    "\n",
    "To mitigate the risks of runtime disconnection or memory errors during long inference sessions, we implement a **Resumable Extraction Loop**.\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "* **Checkpointing:** The function scans the output file before starting to identify which `claim_id`s have already been processed, skipping them to avoid redundancy.\n",
    "* **Stream Saving (JSONL):** Instead of waiting to save the entire list at the end, each processed claim is immediately written to disk as a new line.\n",
    "* **Crash Safety:** We use `f_out.flush()` and `os.fsync()` to force the operating system to write the data to the physical drive immediately, preventing data loss if the kernel crashes."
   ],
   "metadata": {
    "id": "Ft8R5M04KdqB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the path where the claims from 5.1 have been stored\n",
    "\n",
    "claims_path = \"/content/drive/MyDrive/TFM/data/output/Gemma_2_9b-it_processed_claims.json\" #Comment or uncomment depending on the environment\n",
    "# claims_path = \"/kaggle/input/processed-claims/Gemma_2_9B-it_processed_claims.json\"\n",
    "\n",
    "def run_resumable_extraction(input_path, output_path, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Runs the entity extraction pipeline with checkpointing and crash-safe saving.\n",
    "    \"\"\"\n",
    "    # 1. Load Input Data\n",
    "    if not os.path.exists(input_path):\n",
    "        raise FileNotFoundError(f\"Corpus not found at {input_path}\")\n",
    "\n",
    "    print(f\"Loading input corpus from: {input_path}\")\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Convert dict to list if necessary (handling different 5.1 output formats)\n",
    "    corpus = list(data.values()) if isinstance(data, dict) else data\n",
    "\n",
    "    # 2. Checkpoint System: Load already processed IDs\n",
    "    processed_ids = set()\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"\ud83d\udd04 Found existing output file. Scanning for completed claims...\")\n",
    "        with open(output_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    line = line.strip()\n",
    "                    if not line: continue\n",
    "                    record = json.loads(line)\n",
    "                    # Check for ID in both common key formats\n",
    "                    cid = record.get(\"claim_id\", record.get(\"id\"))\n",
    "                    if cid:\n",
    "                        processed_ids.add(cid)\n",
    "                except json.JSONDecodeError:\n",
    "                    continue # Skip partial/corrupted lines\n",
    "        print(f\"\u23e9 Resuming: {len(processed_ids)} claims already completed.\")\n",
    "    else:\n",
    "        print(\"\ud83c\udd95 Starting fresh extraction.\")\n",
    "\n",
    "    # 3. Open Output File in APPEND Mode ('a')\n",
    "    with open(output_path, 'a', encoding='utf-8') as f_out:\n",
    "\n",
    "        # Iterate through corpus\n",
    "        for item in tqdm(corpus, desc=\"Processing Claims\", colour=\"blue\"):\n",
    "\n",
    "            # Identify ID (Handle potential key variations)\n",
    "            claim_id = item.get(\"claim_id\", item.get(\"id\"))\n",
    "\n",
    "            # --- CHECKPOINT: Skip if already done ---\n",
    "            if claim_id in processed_ids:\n",
    "                continue\n",
    "\n",
    "            if not isinstance(item, dict):\n",
    "                continue\n",
    "\n",
    "            # --- INFERENCE ---\n",
    "            input_payload = {\n",
    "                \"id\": claim_id,\n",
    "                \"text\": item.get(\"claim_text\", item.get(\"text\", \"\"))\n",
    "            }\n",
    "\n",
    "            try:\n",
    "                # Use our robust extraction function from Section 4\n",
    "                result = extract_entities_2(\n",
    "                    model=model,\n",
    "                    tokenizer=tokenizer,\n",
    "                    input_data=input_payload,\n",
    "                    streaming=False,\n",
    "                    thinking=False\n",
    "                )\n",
    "\n",
    "                # --- MERGE ---\n",
    "                merged_item = item.copy()\n",
    "                extracted = result.get(\"entities\", []) if isinstance(result, dict) else []\n",
    "                merged_item[\"entities\"] = extracted\n",
    "\n",
    "                # --- IMMEDIATE SAVE ---\n",
    "                # Write as a single line JSON (JSONL format)\n",
    "                f_out.write(json.dumps(merged_item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "                # FORCE WRITE TO DISK (Crucial for crash safety)\n",
    "                f_out.flush()\n",
    "                os.fsync(f_out.fileno())\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\u26a0\ufe0f Error processing {claim_id}: {e}\")\n",
    "                continue\n",
    "\n",
    "    print(f\"\\n\u2705 Extraction process finished. Results saved to {output_path}\")"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-26T16:13:16.671449Z",
     "iopub.execute_input": "2026-01-26T16:13:16.672192Z",
     "iopub.status.idle": "2026-01-26T16:13:16.68112Z",
     "shell.execute_reply.started": "2026-01-26T16:13:16.672161Z",
     "shell.execute_reply": "2026-01-26T16:13:16.680454Z"
    },
    "id": "pcLFtiRT6X9h"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8. Execution of Full Corpus Processing\n",
    "\n",
    "We execute the resumable extraction pipeline.\n",
    "\n",
    "**Note on Reliability:**\n",
    "\n",
    "* If the session crashes or disconnects (common with long LLM inference tasks), simply re-run this cell.\n",
    "\n",
    "* The function detects the results_checkpoint.jsonl file, reads the IDs present, and automatically resumes from the last successfully saved claim."
   ],
   "metadata": {
    "id": "7gF7g3AkLAWk"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the checkpoint path (Intermediate crash-safe storage)\n",
    "checkpoint_path = \"results_checkpoint_5_2.jsonl\"\n",
    "\n",
    "# --- Execution ---\n",
    "# If it crashes at item 500/1000, just run this exact same code again.\n",
    "# It will instantly skip the first 500 and start at 501.\n",
    "run_resumable_extraction(\n",
    "    input_path=claims_path,\n",
    "    output_path=checkpoint_path,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-26T16:13:49.276541Z",
     "iopub.execute_input": "2026-01-26T16:13:49.277391Z",
     "iopub.status.idle": "2026-01-26T18:13:32.616Z",
     "shell.execute_reply.started": "2026-01-26T16:13:49.277359Z",
     "shell.execute_reply": "2026-01-26T18:13:32.615187Z"
    },
    "id": "vhio8Cd16X9h",
    "outputId": "0486799c-8c9f-451c-aeb1-7095db79ce20"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "\ud83d\udd04 Found existing output file. Scanning for completed claims...\n\u23e9 Resuming: 1 claims already completed.\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Processing Claims: 100%|\u001b[34m\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u001b[0m| 730/730 [1:59:43<00:00,  9.84s/it]  ",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "\n\u2705 Extraction process finished. Results saved to results_checkpoint.jsonl\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 9. Data Inspection and Verification\n",
    "\n",
    "After the batch extraction concludes, we perform a final inspection of the structured records. This ensures that the merging of the original claim metadata with the new `entities` list was successful and that the data is ready for the **Relation Extraction (5.3)** phase.\n",
    "\n"
   ],
   "metadata": {
    "id": "9sCTR_4ZLXy-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Path to the crash-safe checkpoint file\n",
    "# path = \"/kaggle/working/results_checkpoint.jsonl\"\n",
    "path = \"/content/drive/MyDrive/TFM/data/output/results_checkpoint_5_2.jsonl\"\n",
    "data = []\n",
    "\n",
    "# Load the records back into a list for inspection\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line:  # skip empty lines\n",
    "            try:\n",
    "                data.append(json.loads(line))\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Skipping malformed line: {e}\")\n",
    "\n",
    "print(f\"\u2705 Successfully loaded {len(data)} records from checkpoint.\")\n",
    "\n",
    "# --- Sanity Check: Display Top 5 Records ---\n",
    "# We use json.dumps for a pretty-printed view of the structure\n",
    "\n",
    "print(json.dumps(data[:5], indent=2, ensure_ascii=False))"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-26T18:17:32.847035Z",
     "iopub.execute_input": "2026-01-26T18:17:32.847563Z",
     "iopub.status.idle": "2026-01-26T18:17:32.865199Z",
     "shell.execute_reply.started": "2026-01-26T18:17:32.847534Z",
     "shell.execute_reply": "2026-01-26T18:17:32.864571Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "id": "Ub6weoKL6X9h",
    "outputId": "f26dd551-3388-418f-f491-b089c75c1b86"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Loaded 730 records\n",
     "output_type": "stream"
    },
    {
     "execution_count": 176,
     "output_type": "execute_result",
     "data": {
      "text/plain": "[{'claim_id': 'claim_0001',\n  'arxiv_id': '2406.01263v2',\n  'claim_text': 'Measurements of resistivity, thermal expansion, specific heat, and Seebeck coefficient show anomalies at certain temperatures (T*) for LaO0.5F0.5Bi1-xPbxS2 (x\u22650.08).',\n  'metadata': {'Source ID': '2406.01263v2',\n   'Study Type': 'Experimental',\n   'Epistemic Type': 'Observation',\n   'Polarity': 'Neutral'},\n  'physical_attributes': {'Subject': 'LaO0.5F0.5Bi1-xPbxS2 (x\u22650.08)',\n   'Driver': 'Pb substitution',\n   'Effect': 'Anomalies at T*'},\n  'entities': [{'text': 'resistivity', 'label': 'Property'},\n   {'text': 'thermal expansion', 'label': 'Property'},\n   {'text': 'specific heat', 'label': 'Property'},\n   {'text': 'Seebeck coefficient', 'label': 'Property'},\n   {'text': 'anomalies', 'label': 'State'},\n   {'text': 'LaO0.5F0.5Bi1-xPbxS2', 'label': 'Material'},\n   {'text': 'x\u22650.08', 'label': 'Condition'}]},\n {'claim_id': 'claim_0002',\n  'arxiv_id': '2406.01263v2',\n  'claim_text': 'Large thermal expansion anomalies, specific heat anomalies, and the existence of hystereses in the resistivity, thermal expansion, specific heat, and Seebeck coefficient measurements indicate a first-order structural phase transition at T* in LaO0.5F0.5Bi1-xPbxS2 (x\u22650.08).',\n  'metadata': {'Source ID': '2406.01263v2',\n   'Study Type': 'Experimental',\n   'Epistemic Type': 'Inference',\n   'Polarity': 'Neutral'},\n  'physical_attributes': {'Subject': 'LaO0.5F0.5Bi1-xPbxS2 (x\u22650.08)',\n   'Driver': 'Pb substitution',\n   'Effect': 'First-order structural phase transition at T*',\n   'Mechanism': 'Not Explicitly Stated'},\n  'entities': [{'text': 'thermal expansion anomalies', 'label': 'State'},\n   {'text': 'specific heat anomalies', 'label': 'State'},\n   {'text': 'hystereses', 'label': 'State'},\n   {'text': 'resistivity', 'label': 'Property'},\n   {'text': 'thermal expansion', 'label': 'Property'},\n   {'text': 'specific heat', 'label': 'Property'},\n   {'text': 'Seebeck coefficient', 'label': 'Property'},\n   {'text': 'first-order structural phase transition', 'label': 'State'},\n   {'text': 'T*', 'label': 'Property'},\n   {'text': 'LaO0.5F0.5Bi1-xPbxS2', 'label': 'Material'},\n   {'text': 'x\u22650.08', 'label': 'Condition'}]},\n {'claim_id': 'claim_0003',\n  'arxiv_id': '2406.01263v2',\n  'claim_text': 'The anomalies at T* in LaO0.5F0.5Bi1-xPbxS2 (x\u22650.08) are related to both the lattice system and the electronic system.',\n  'metadata': {'Source ID': '2406.01263v2',\n   'Study Type': 'Experimental',\n   'Epistemic Type': 'Inference',\n   'Polarity': 'Neutral'},\n  'physical_attributes': {'Subject': 'LaO0.5F0.5Bi1-xPbxS2 (x\u22650.08)',\n   'Driver': 'Pb substitution',\n   'Effect': 'Anomalies at T*'},\n  'entities': [{'text': 'LaO0.5F0.5Bi1-xPbxS2', 'label': 'Material'},\n   {'text': 'T*', 'label': 'Property'},\n   {'text': 'lattice system', 'label': 'State'},\n   {'text': 'electronic system', 'label': 'State'},\n   {'text': 'x\u22650.08', 'label': 'Condition'}]},\n {'claim_id': 'claim_0004',\n  'arxiv_id': '2406.01263v2',\n  'claim_text': 'Superconductivity is not observed above 2 K at x=0.08 in LaO0.5F0.5Bi1-xPbxS2.',\n  'metadata': {'Source ID': '2406.01263v2',\n   'Study Type': 'Experimental',\n   'Epistemic Type': 'Observation',\n   'Polarity': 'Neutral'},\n  'physical_attributes': {'Subject': 'LaO0.5F0.5Bi1-xPbxS2 (x=0.08)',\n   'Driver': 'Pb substitution',\n   'Effect': 'No superconductivity above 2 K'},\n  'entities': [{'text': 'Superconductivity', 'label': 'State'},\n   {'text': '2 K', 'label': 'Measurement Value'},\n   {'text': 'x=0.08', 'label': 'Condition'},\n   {'text': 'LaO0.5F0.5Bi1-xPbxS2', 'label': 'Material'}]},\n {'claim_id': 'claim_0005',\n  'arxiv_id': '2406.01263v2',\n  'claim_text': 'The suppression of superconductivity around the structural phase boundary at x=0.08 suggests a close relationship between the lattice structure and superconductivity in LaO0.5F0.5Bi1-xPbxS2.',\n  'metadata': {'Source ID': '2406.01263v2',\n   'Study Type': 'Experimental',\n   'Epistemic Type': 'Inference',\n   'Polarity': 'Neutral'},\n  'physical_attributes': {'Subject': 'LaO0.5F0.5Bi1-xPbxS2',\n   'Driver': 'Structural phase boundary at x=0.08',\n   'Effect': 'Suppression of superconductivity'},\n  'entities': [{'text': 'superconductivity', 'label': 'State'},\n   {'text': 'structural phase boundary', 'label': 'State'},\n   {'text': 'x=0.08', 'label': 'Condition'},\n   {'text': 'LaO0.5F0.5Bi1-xPbxS2', 'label': 'Material'},\n   {'text': 'lattice structure', 'label': 'Property'}]}]"
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 10. Final Archiving and Persistence\n",
    "\n",
    "To conclude this module, we export the verified records into a timestamped JSON file. This serves as the \"source of truth\" for the subsequent Knowledge Graph construction stages.\n",
    "\n",
    "By using a dynamic naming convention, we maintain a clear audit trail of the extraction runs, allowing for side-by-side comparison of different model versions or prompt iterations."
   ],
   "metadata": {
    "id": "4CdFfNVwLwf9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# --- Final Archiving ---\n",
    "# Capture the current timestamp for versioning\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = f\"Qwen_3_8B_ProcessedClaimsAndEntities_{timestamp}.json\"\n",
    "# path = f\"/kaggle/working/{filename}\"\n",
    "path = f\"/content/drive/MyDrive/TFM/data/output/{filename}\"\n",
    "# Persist the list to a formatted JSON file\n",
    "with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "\n",
    "print(f\"\u2705 Final dataset successfully archived at: {path}\")"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-26T18:24:01.944199Z",
     "iopub.execute_input": "2026-01-26T18:24:01.945027Z",
     "iopub.status.idle": "2026-01-26T18:24:01.977787Z",
     "shell.execute_reply.started": "2026-01-26T18:24:01.944995Z",
     "shell.execute_reply": "2026-01-26T18:24:01.97712Z"
    },
    "id": "BR1Oj7-F6X9h",
    "outputId": "87c9116d-470d-4c91-ba14-833d3442bc88"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Saved to /kaggle/working/Qwen_3_8B_ProcessedClaimsAndEntities_20260126_182401.json\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Final Checkpoint Summary (Notebook 5.2)\n",
    "\n",
    "1. **Model Setup:** Qwen 3 (8B) loaded with `float16` precision and optimized for GPU inference.\n",
    "2. **Gold Standard:** Defined 6 strict extraction examples to benchmark performance.\n",
    "3. **Metrics:** Calculated Precision, Recall, and F1-score to validate LLM performance.\n",
    "4. **Resumable Loop:** Processed the full corpus with crash-safety and progress monitoring.\n",
    "5. **Output:** Structured JSON file linking **Claims** to **Chemical Materials**, **Physical Properties**, and **Measurement Values**.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "The entities yextracted are currently \"flat\"\u2014they exist as a list within each claim. In the next stage (**Notebook 5.3: Relation Extraction**), we will perform the most vital step for the Knowledge Graph: **linking them.**\n"
   ],
   "metadata": {
    "id": "hogMhH6VLtic"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "trusted": true,
    "id": "rqYyMVi56X9h"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}